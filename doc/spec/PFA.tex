\documentclass{article}
\usepackage{fullpage}
\usepackage[]{hyperref}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{xcolor}
\usepackage{amsthm}
\usepackage{fancyvrb}

\newcommand{\PFAc}{\ttfamily\bfseries}
\newcommand{\PFAp}{\ttfamily\bfseries}
\newcommand{\PFAt}{\ttfamily\bfseries}
\newcommand{\PFAtp}{\ttfamily\bfseries}
\newcommand{\PFApf}{\ttfamily\bfseries}
\newcommand{\PFAf}{\ttfamily\bfseries}

\newenvironment{description*}%
  {\vspace{-0.15 cm}\begin{description}%
    \setlength{\itemsep}{3pt}%
    \setlength{\parskip}{0pt}}%
  {\vspace{-0.25 cm}\end{description}}

\newenvironment{allowedfields}%
  {\begin{center} \begin{minipage}{0.9\linewidth} \begin{description}}%
  {\end{description} \end{minipage} \end{center}}

\hypersetup{colorlinks=true, allcolors=blue}

\theoremstyle{definition}
\newtheorem{example}{Example}[section]

\newenvironment{json}{
  \VerbatimEnvironment
  \begin{center}\begin{minipage}{0.9\linewidth}
  \begin{Verbatim}[formatcom=\ttfamily\bfseries]}{\end{Verbatim}\end{minipage}\end{center}}

\title{PFA: Portable Format for Analytics}
\author{Jim Pivarski}
\date{Sometime in 2014}

\input{libfcns}

\setlength{\parskip}{0.15 cm}
\begin{document}
\maketitle

{\large \bf Abstract}
\vspace{0.25 cm}

This specification defines the syntax and semantics of the Portable Format for Analytics (PFA).

PFA is a mini-language for mathematical calculations that is usually generated programmatically, rather than by hand.  A PFA document is a string of JSON-formatted text that describes an executable called a scoring engine.  Each engine has a well-defined input, a well-defined output, and functions for combining inputs to construct the output in an expression-centric syntax tree.  In addition, it has centralized facilities for maintaining state, with well-defined semantics for sharing state among scoring engines in a thread-safe way.  The specification defines a suite of mathematical and statistical functions for transforming data, but it does not define any means of communication with an operating system, file system, or network.  A PFA engine must be embedded in a larger system that has these capabilities, and thus an analytic workflow is decoupled into a part that manages data pipelines (such as Hadoop, Storm, or Akka), and a part that describes the algorithm to be performed on data (PFA).  

PFA is similar to the Predictive Model Markup Language (PMML), an XML-based specification for statistical models, but whereas PMML's focus is on statistical models in the abstract, PFA's focus is on the scoring procedure itself.  The same input given to two PFA-enabled systems must yield the same output, regardless of platform (e.g.\ a JVM in Hadoop, a client's web browser, a GPU kernel function, or even an IP core directly embedded in an integrated circuit).  Unlike PMML, the PFA specification defines the exact bit-for-bit behavior of any well-formed document, the semantics of data types and data structures, including behavior in concurrent systems, and all cases in which an exception should be thrown.  Like PMML, PFA is a specification, not an implementation, it defines a suite of statistical algorithms for analyzing data, and it is usually generated programmatically, as the output of a machine learning algorithm, for instance.

\vspace{0.5 cm}
{\large \bf Status of this document}
\vspace{0.25 cm}

{\it This section describes the status of this document at the time of the current draft.  Other documents may supersede this document.}

This document is an early draft that has not been endorsed for recommendation by any organization.  It describes a proposed specification that could, in the future, become a standard.

\pagebreak

\tableofcontents

\pagebreak

\section{Introduction}

\subsection{Motivation for PFA}

The Portable Format for Analytics (PFA) is a mini-language for mathematical calculations.  It differs from most programming languages in that it is optimized for automatic code generation, rather than writing programs by hand.  The primary use-case is to represent the output of machine learning algorithms, such that they can be freely moved between systems.  Traditionally, this field has been dominated by special-purpose file formats, each representing only one type of statistical model.  The Predictive Model Markup Language (PMML) provides a means of unifing the most common model types into one file format.  However, PMML can only express a fixed set of pre-defined model types; new model types must be agreed upon by the Data Mining Group (DMG) and integrated into a new version of PMML, then that new version must be adopted by the community before it is widely usable.

PFA represents models and analytic procedures more generally by providing generic programming constructs, such as conditionals, loops, persistent state, and callback functions, in addition to a basic suite of statistical tools.  Conventional models like regression, decision trees, and clustering are expressed by referencing the appropriate library function, just as in PMML, but new models can be expressed by composing library functions or passing user-defined callbacks.  Most new statistical techniques are variants of old techniques, so a small number of functions with the appropriate hooks for inserting user code can represent a wide variety of methods, many of which have not been discovered yet.

Given that flexibility is important, one might consider using a general purpose programming language, such as C, Java, Python, or especially R, which is specifically designed for statistics.  While this is often the easiest method for small problems that are explored, formulated, and solved on an analyst's computer, it is difficult to scale up to network-sized solutions or to deploy on production systems that need to be more carefully controlled than a personal laptop.  The special-purpose code may depend on libraries that cannot be deployed, or may even be hard to identify exhaustively.  In some cases, the custom code might be regarded as a stability or security threat that must be thoroughly reviewed before deployment.  If the analytic algorithm needs to be deployed multiple times before it is satisfactory and each deployment is reviewed for reasons unrelated to its analytic content, development would be delayed unnecessarily.  This problem is solved by decoupling the analytic workflow into a part that deals exclusively with mathematics (the PFA scoring engine) and the rest of the infrastructure (the PFA host).  A mathematical algorithm implemented in PFA can be updated frequently with minimal review, since PFA is incapable of raising most stability or security issues, due to its limited access.

PFA is restricted to the following operations: mathematical functions on numbers, strings, raw bytes, homogeneous lists, homogeneous maps (also known as hash-tables, associative arrays, or dictionaries), heterogeneous records, and unions of the above, where mathematical functions include basic operations, special functions, data sturcture manipulations, missing data handling, descriptive statistics, and common model types such as regression, decision trees, and clustering, parameterized for flexibility.  PFA does not include any means of accessing the operating system, the file system, or the network, so a rouge PFA engine cannot expose or manipulate data other than that which is intentionally funneled into it by the host system.  The full PFA specification allows recursion and unterminated loops, but execution time is limited by a timeout.  PFA documents may need to be reviewed for mathematical correctness, but they do not need to be reviewed for safety.

Another reason to use PFA as an intermediate model representation is for simplicity of code generation.  A machine learning algorithm generates an executable procedure, usually a simple, parameterized decider algorithm that categorizes or makes predictions based on new data.  Although the parameters might be encoded in a static file, some component must be executable.  A PFA document bundles the executable with its parameters, simplifying version control.

The syntax of PFA is better suited to automatic code generation than most programming languages.  Many languages have complex syntax to accomodate the way people think while programming, including infix operators, a distinction between statements and expressions, and in some cases even meaningful whitespace.  Though useful when writing programs by hand, these features only complicate automatic code generation.  A PFA document is an expression tree rendered in JSON, and trees are easy to programmatically compose into larger trees without introducing syntax errors in the generated code.  This is well-known in the Lisp community, since the ease of writing code-modifying macros in Lisp is often credited to its exclusive use of expression trees, rendered as parenthesized lists (known as S-expressions).  PFA uses JSON, rather than S-expressions, because libraries for manipulating JSON objects are more widely available and JSON provides a convenient syntax for maps, but the transliteration between JSON and S-expressions is straight-forward.

Another benefit of PFA's simplicity relative to general programming languages is that it is more amenable to static analysis.  A PFA host can more thoroughly examine an incoming PFA document for undesirable features.  Although PFA makes use of callback functions to provide generic algorithms, functions are not first-class objects in the language, meaning that they cannot be dynamically assigned to variables.  The identity of every function call can be determined without running the engine, which makes it possible to statically generate a graph of function calls and identify recursive loops.  In very limited runtime environments, such as some GPUs, the compiler implicitly inlines all function calls, so recursion is not possible.  In cases like these, static analysis of the PFA document is a necessary step in generating the executable.

A PFA document can also be statically type-checked.  This allows for faster execution times, since types do not need to be checked at run-time, but it also provides additional safety to the PFA host.

PFA uses Apache Avro schemae for type annotations.  Avro is an open-source serialization protocol, widely used in Hadoop and related projects, whose type schemae are expressed as JSON objects and whose data structures can be expressed as JSON objects.  Therefore, all parts of the PFA engine, including control structures, type annotations, and embedded data are all expressed in one seamless JSON object.  Avro additionally has well-defined rules to resolve different but possibly compatible schemae, which PFA reinterprets as type promotion (allowing integers to be passed to a function that expects floating-point numbers, for instance).  When interpreted this way, Avro also has a type-safe null, which PFA uses to ensure that missing data are always explicitly handled.  Finally, the input and output of every PFA engine can always be readily (de)serialized into Avro's binary format or JSON representation, since Avro libraries are available on a wide variety of platforms.

\subsection{Terminology used in this specification}

Within this specification, the key words ``MUST'', ``MUST NOT'', ``REQUIRED'', ``SHALL'', ``SHALL NOT'', ``SHOULD'', ``SHOULD NOT'', ``RECOMMENDED'', ``MAY'', and ``OPTIONAL'' are to be interpreted as described in RFC 2119 (see \href{http://www.ietf.org/rfc/rfc2119.txt}{RFC2119}).  However, for readability, these words do not appear in all uppercase letters in this specification.

At times, this specification provides hints and suggestions for implementation.  These suggestions are not normative and conformance with this specification does not depend on their realization.  These hints contain the expression ``We suggest\ldots'', ``Specific implementations may\ldots'', or similar wording.

This specification uses the terms ``JSON object'', ``JSON object member name'', ``JSON object member value'', ``JSON array'', ``JSON array value'', ``number'', ``integer'', ``string'', ``boolean'', and ``null'' as defined in the JSON specification (\href{http://tools.ietf.org/html/rfc4627}{RFC-4627}), sections 2.2 through 2.5.  It also references and quotes sections of the Avro 1.7.6 specification (\url{http://avro.apache.org/docs/1.7.6/spec.html}).

\subsection{PFA MIME type and file name extension}

The recommended MIME type for PFA is ``application/pfa+json'', though this is not yet in the process of standardization.

It is recommended that PFA files have the extension ``.pfa'' (all lowercase) on all platforms.  It is recommended that gzip-compressed PFA files have the extension ``.pfaz'' (all lowercase) on all platforms.

\hypertarget{hsec:conformance}{}
\subsection{Levels of PFA conformance and PFA subsets}
\label{sec:conformance}

PFA is a large specification with many modules, so some projects or vendors may wish to implement some but not all of the specification.  However, interoperability is the reason PFA exists; if an implementation does not adhere to the standard, it has limited value.  It is therefore useful to explicitly define what it means for a system to partially implement the standard.

JSON subtrees of a PFA document are interpreted in the following five contexts.
\begin{itemize}
\item Top-level fields are JSON object member name, value pairs in the outermost JSON object of the PFA document.  They have unique member names and describe global aspects of the scoring engine.
\item Special forms are JSON objects that specify executable expressions and function definitions.  Each is associated with a unique name.
\item Library functions are strings that specify routines not defined in the PFA document itself.  Each is associated with a unique name that does not conflict with any of the special forms' names.
\item Avro type schemae are JSON objects and strings that describe data types.  The syntax and meaning of Avro types are specified in \href{http://avro.apache.org/docs/1.7.6/spec.html}{the Avro 1.7.6 specification}.
\item Embedded data are JSON objects, JSON arrays, numbers, integers, strings, booleans, and nulls that describe data structures.  The syntax and meaning of these objects are also defined by Avro, as the format used by the {\PFAc JSONEncoder} and {\PFAc JSONDecoder}.
\end{itemize}

A system may be partially PFA compliant if it implements some but not all top-level fields, some but not all special forms, or some but not all library functions.  Its coverage may be specified by listing the object member names of the top-level fields that it does implement, the names of the special forms that it does implement, and the names of the library functions that it does implement.  Those top-level fields, special forms, and library functions that it does implement must be completely and correctly implemented.  The coverage is therefore atomic and one can immediately determine if a particular system can execute a particular PFA document by checking the set of names used by the document against the set of names implemented by the system.

Some special forms and library functions make use of some top-level fields.  For example, library functions that generate random numbers use the {\PFAc randseed} field for configuration.  These special forms and library functions cannot be considered implemented unless the corresponding top-level fields are also implemented.  The dependencies are explicitly defined in this specification.

Avro type schemae and JSON-encoded data should be completely implemented, to the extent defined by the Avro specification.  We suggest that implementations use language-specific Avro libraries as much as possible, rather than implementing Avro-related features in a PFA system.

The PFA standard is defined so that a PFA-compliant system can verify that the JSON types of a PFA document are correctly composed (syntax check), verify that the PFA invariants are maintained and Avro data types are correctly composed (semantic check), and impose additional constraints on the set of top-level fields, special forms, and library functions used (optional checks).  A PFA-compliant system should perform the syntax and semantic checks, including all type inference and type checking, but it is not required.  A PFA document that does not satisfy these invariants and type constraints is not valid and its behavior is not defined by this specification.  The third set of checks, however, is completely optional and different systems may apply different constraints on the kinds of scoring engines they are willing to execute.  For instance, an implementation targeting a limited environment in which recursion is not possible may analyze the document and reject it if any recursive loops are found.

This specification does not define any standardized subsets of PFA.  As stated above, partial conformance is defined by ad hoc subsets of atomic units.  However, as experience develops, the community may define industry-standard subsets of PFA for specific purposes or special environments.  Conforming to a standardized subset would provide better interoperability than defining ad hoc subsets, and we would recommend such a standard when it exists.  At present, we can only recommend a well-chosen ad hoc subset or complete conformance.

\pagebreak

\section{PFA document structure}

A PFA document is a serialized JSON object representing an executable scoring engine.  Only the following JSON object member names may appear at this JSON nesting level.  These are the top-level fields referred to in the \hyperlink{hsec:conformance}{conformance section} of this specification.  Three fields, {\PFAc action}, {\PFAc input}, and {\PFAc output}, are required for every PFA document and are therefore required for every PFA implementation.  The rest are optional for PFA documents and not strictly required for PFA implementations.  As explained in the conformance section, not implementing some top-level fields can make some special forms and functions unimplementable.

\begin{allowedfields}
\item[\PFAc name:] A string used to identify the scoring engine (has no effect on calculations).
\item[\PFAc method:] A string that may be ``map'', ``emit'', or ``fold'' (\hyperlink{hsec:method}{see Sec.~\ref{sec:method}}).  If absent, the default value is ``map''.
\item[\PFAc input:] An Avro schema representing the data type of data provided to the scoring engine (\hyperlink{hsec:input-output}{see Sec.~\ref{sec:input-output}}).
\item[\PFAc output:] An Avro schema representing the data type of data produced by the scoring engine (\hyperlink{hsec:input-output}{see Sec.~\ref{sec:input-output}}).  The way that output is returned to the host system depends on the {\PFAc method}.
\item[\PFAc begin:] An \hyperlink{hsec:expressions}{expression} or JSON array of \hyperlink{hsec:expressions}{expressions} that are executed in the begin phase of the scoring engine's run (\hyperlink{hsec:phases}{see Sec.~\ref{sec:phases}}).
\item[\PFAc action:] An \hyperlink{hsec:expressions}{expression} or JSON array of \hyperlink{hsec:expressions}{expressions} that are executed for each input datum in the active phase of the scoring engine's run (\hyperlink{hsec:phases}{see Sec.~\ref{sec:phases}}).
\item[\PFAc end:] An \hyperlink{hsec:expressions}{expression} or JSON array of \hyperlink{hsec:expressions}{expressions} that are executed in the end phase of the scoring engine's run (\hyperlink{hsec:phases}{see Sec.~\ref{sec:phases}}).
\item[\PFAc fcns:] A JSON object whose member values are \hyperlink{hsec:fcndef}{function definitions}, defining routines that may be called by expressions in {\PFAc begin}, {\PFAc action}, {\PFAc end}, or by expressions in other functions.
\item[\PFAc zero:] Embedded JSON data whose type must match the {\PFAc output} type of the engine.  This is only used by the ``fold'' method to initialize the fold aggregation.  If {\PFAc method} is ``map'' or ``emit'', this field is ignored.
\item[\PFAc cells:] A JSON object whose member values specify statically allocated, named, typed units of persistent state or embedded data (\hyperlink{hsec:state}{see Sec.~\ref{sec:state}}).  The format of this JSON object is restricted: \hyperlink{hsec:cells-pools}{see Sec.~\ref{sec:cells-pools}}.
\item[\PFAc pools:] A JSON object whose member values specify dynamically allocated namespaces of typed persistent state (\hyperlink{hsec:state}{see Sec.~\ref{sec:state}}).  The format of this JSON object is restricted: \hyperlink{hsec:cells-pools}{see Sec.~\ref{sec:cells-pools}}.
\item[\PFAc randseed:] An integer which, if present, sets the seed for pseudorandom number generation (\hyperlink{hsec:method}{see Sec.~\ref{sec:random}}).
\item[\PFAc doc:] A string used to describe the scoring engine or its provenance (has no effect on calculations).
\item[\PFAc metadata:] A JSON object, array, string, number, boolean, or null used to describe the scoring engine or its provenance (has no effect on calculations).
\item[\PFAc options:] A JSON object of JSON objects, arrays, strings, numbers, booleans, or nulls used to control execution.  The format of this JSON object is restricted: see \hyperlink{hsec:options}{see Sec.~\ref{sec:options}}.
\end{allowedfields}

\noindent \begin{minipage}{\linewidth}
\begin{example}
This is the simplest possible PFA document.  It only reads {\PFAc null} values, returns {\PFAc null} values, and performs no calculations.
\begin{json}
{"input": "null", "output": "null", "action": null}
\end{json}
\end{example}
\end{minipage}

\begin{example}
This is a simple yet non-degenerate PFA document.  It increments numerical input by 1.
\begin{json}
{"input": "double", "output": "double", "action": {"+": ["input", 1]}}
\end{json}
\end{example}

\begin{example}
This example implements a small decision tree.  Input data are records with three fields: ``one'' (integer), ``two'' (double), and ``three'' (string).  The decision tree is stored in a cell named ``tree'' with type ``TreeNode''.  The tree has three binary splits (four leaves).  The scoring engine walks from the root to a leaf for each input datum, choosing a path based on values found in the record's fields, and returns the string it finds at the tree's leaf.  (See the definition of the \hyperlink{model.tree.simpleWalk}{model.tree.simpleWalk} function.)
\begin{json}
{"input": {"type": "record", "name": "Datum", "fields":
   [{"name": "one", "type": "int"},
    {"name": "two", "type": "double"},
    {"name": "three", "type": "string"}]},
 "output": "string",
 "cells": {"tree":
             {"type":
               {"type": "record",
                "name": "TreeNode",
                "fields": [
                  {"name": "field", "type": "string"},
                  {"name": "operator", "type": "string"},
                  {"name": "value", "type": ["double", "string"]},
                  {"name": "pass", "type": ["string", "TreeNode"]},
                  {"name": "fail", "type": ["string", "TreeNode"]}]},
              "init":
                {"field": "one",
                 "operator": "<",
                 "value": {"double": 12},
                 "pass":
                   {"TreeNode":
                     {"field": "two",
                      "operator": ">",
                      "value": {"double": 3.5},
                      "pass": {"string": "yes-yes"},
                      "fail": {"string": "yes-no"}}},
                 "fail":
                   {"TreeNode":
                     {"field": "three",
                      "operator": "==",
                      "value": {"string": "TEST"},
                      "pass": {"string": "no-yes"},
                      "fail": {"string": "no-no"}}}}}},
 "action":
   {"model.tree.simpleWalk": ["input", {"cell": "tree"}]}}
\end{json}
\end{example}

\hypertarget{hsec:cells-pools}{}
\subsection{Cells and Pools}
\label{sec:cells-pools}

The {\PFAc cells} and {\PFAc pools} top-level fields, if present, are JSON objects whose member values are cell-specifications or pool-specifications, respectively.  A cell is a mutable, global data store that holds a single value with a specific type, and a pool is a mutable map from dynamically allocated names to values of a specific type (\hyperlink{hsec:state}{see Sec.~\ref{sec:state}}).

A cell-specification is a JSON object with the following fields.
\begin{allowedfields}
\item[\PFAc type:] {\it (required)} An Avro schema representing the data type of this cell.
\item[\PFAc init:] {\it (required)} Embedded JSON whose type must match {\PFAc type}.  This is the initial value of the cell (or constant value if it is never modified).
\item[\PFAc shared:] An optional boolean specifying whether this cell is thread-local to one scoring engine or shared among a battery of similar engines (\hyperlink{hsec:concurrent}{see Sec.~\ref{sec:concurrent}}).  The default is false.
\end{allowedfields}

A pool-specification is a JSON object with the following fields.
\begin{allowedfields}
\item[\PFAc type:] {\it (required)} An Avro schema representing the data type of this pool.
\item[\PFAc init:] JSON object whose member values are embedded JSON that must match {\PFAc type}.  Unlike a cell, a pool may be empty on initialization, in which case {\PFAc init} is either unspecified or {\PFAc \{\}}.
\item[\PFAc shared:] An optional boolean specifying whether this pool is thread-local to one scoring engine or shared among a battery of similar engines (\hyperlink{hsec:concurrent}{see Sec.~\ref{sec:concurrent}}).  The default is false.
\end{allowedfields}

A complete explanation of cells and pools is given in \hyperlink{hsec:state}{Sec.~\ref{sec:state}}.

\hypertarget{hsec:options}{}
\subsection{Engine options}
\label{sec:options}

The top-level field {\PFAc options}, if present, is a JSON object whose member names must be chosen from the following.  Each member name is associated with a particular JSON type, also specified below.  See \hyperlink{hsec:state}{Sec.~\ref{sec:control}} for a complete explanation of the overridable options framework.
\begin{allowedfields}
\item[\PFAc timeout:] {\it (integer)} If positive, the maximum number of milliseconds before a single execution of {\PFAc begin}, {\PFAc action}, or {\PFAc end} throws a \hyperlink{hsec:exceptions}{timeout exception}.  Default is $-1$ (no timeout).
\item[\PFAc timeout.begin:] {\it (integer)} If positive, the maximum number of milliseconds before a single execution of {\PFAc begin} throws a \hyperlink{hsec:exceptions}{timeout exception}.  Overrides {\PFAc timeout} if present and defaults to {\PFAc timeout} if not.
\item[\PFAc timeout.action:] {\it (integer)} If positive, the maximum number of milliseconds before a single execution of {\PFAc action} throws a \hyperlink{hsec:exceptions}{timeout exception}.  Overrides {\PFAc timeout} if present and defaults to {\PFAc timeout} if not.
\item[\PFAc timeout.end:] {\it (integer)} If positive, the maximum number of milliseconds before a single execution of {\PFAc end} throws a \hyperlink{hsec:exceptions}{timeout exception}.  Overrides {\PFAc timeout} if present and defaults to {\PFAc timeout} if not.
\end{allowedfields}

\pagebreak

\section{Scoring engine execution model}

A PFA document (string of JSON-formatted text) describes a PFA scoring engine (executable routine) or a battery of initially identical engines.  An engine behaves as a single-threaded executable with global state (cells and pools) and local variables.  A battery of scoring engines may run in parallel and only share data if some cells or pools are explicitly marked as {\PFAc shared}.  Although a battery of scoring engines generated by a single PFA document start in exactly the same state, they may evolve into different states if they have any unshared cells or pools.

PFA engines are units of work that may fit into a pipeline system such as Hadoop, Storm, or Akka.  In a map-reduce framework like Hadoop, for instance, one PFA document could describe the calculation performed by all of the mappers and another could describe the calculation performed by all of the reducers.  The mappers are a battery of independent PFA engines, as are the reducers.  In pure map-reduce, the mappers would not communicate with each other and the reducers would not communicate with each other, so none of the cells or pools should be marked as {\PFAc shared}.  With this separation of concerns, issues of interpreting input file types and formatting output should be handled by the pipeline system (Hadoop in this case) while the mathematical procedure is handled by PFA.  Changing file formats would require an update to the pipeline code (and possibly a code review), but changing details of the analytic would only require a new PFA document (a JSON configuration file).

\hypertarget{hsec:phases}{}
\subsection{Execution phases of a PFA scoring engine}
\label{sec:phases}

A PFA engine has a 7 phase lifecycle.  These phases are the following, executed in this order:

\vspace{-0.3 cm}
\begin{center}
\begin{minipage}{0.9\linewidth}
\begin{enumerate}
\item reading the PFA document and performing a syntax check;
\item verifying PFA invariants and checking type consistency;
\item additional checks, constraints required by a particular PFA system;
\item initialization of the engine;
\item execution of the {\PFAc begin} routine;
\item execution of the {\PFAc action} routine for each input datum;
\item execution of the {\PFAc end} routine.
\end{enumerate}
\end{minipage}
\end{center}

In phase 1, JSON is decoded and may be used to build an abstract syntax tree of the whole document.  At this stage, JSON types must be correctly matched (e.g.\ if a number is expected, a string cannot be provided instead) to build the syntax tree.  Incorrectly formatted JSON should also be rejected, though we recommend that a dedicated JSON decoder is used for this task.  Avro schemae should also be interpreted in this phase (see \hyperlink{hsec:avro-types}{Sec.~\ref{sec:avro-types}}).

In phase 2, the loaded PFA document is interpreted as an executable.  If the specific PFA implementation builds code with macros, compiles bytecode, or synthesizes a circuit for execution, that work should happen in this phase.  Data types should be inferred and checked (see \hyperlink{hsec:type-inference}{Sec.~\ref{sec:type-inference}}), especially if the executable is compiled.

Phase 3 is provided for optional checks.  Due to limitations of a particular environment, some PFA systems may need to be more restrictive than the general specification and reject what would otherwise be a valid PFA document.  Reasons include unimplemented function calls, inability to implement recursion, or data structures that are too large.  The phase 3 checks may need to be performed concurrently with the phase 2 checks to build the executable.

Phase 4, initialization, is when data structures such as cells and pools are allocated and filled, network connections are established (if relevant for a particular PFA implementation), pseudorandom number generators are seeded, etc.  These are actions that the engine must perform to work properly but are not a part of the {\PFAc begin}, {\PFAc action}, or {\PFAc end} routines.

The actions performed in the last three phases, {\PFAc begin}, {\PFAc action}, and {\PFAc end}, are explicitly defined in the PFA document.  A PFA system must implement the {\PFAc action} phase, since every PFA document must define an {\PFAc action}.  The {\PFAc action} accepts input and returns output, though the way it does so depends on the {\PFAc method} (\hyperlink{hsec:method}{Sec.~\ref{sec:method}}).

The {\PFAc begin} and {\PFAc end} phases do not accept input and do not return output: they can only modify cells and pools, emit log messages, or throw exceptions.  A PFA system is not required to implement {\PFAc begin} and {\PFAc end}.  If a system that does not implement {\PFAc begin} encounters a document that has a {\PFAc begin} routine, it must fail with an error.  If a system that does not implement {\PFAc end} encounters a document that has an {\PFAc end} routine, it need not fail with an error, though it may.  This is because some PFA documents may use {\PFAc begin} to initialize essential data structures and the {\PFAc action} would only function properly if {\PFAc begin} has been executed, but the {\PFAc end} routine can only affect the state of a completed scoring engine whose interpretation is implementation-specific.  Moreover, some data pipelines do not even have a concept of completion, such as Storm.

After all input data have been passed to the scoring engine and the last {\PFAc action} or {\PFAc end} routine has finished, the scoring engine is said to be completed.  This may be considered an eighth phase of the engine, though its behavior at this point is not defined by this specification.  A particular PFA system may extract aggregated results from a completed engine's state and it may even call functions defined in the document's {\PFAc fcn} field, but this is beyond the scope of the standard PFA lifecycle.  (Note: if the primary purpose of a scoring engine is to aggregate data, consider using the ``fold'' {\PFAc method} instead of extracting from the engine's internal state.)

A completed scoring engine may be used to create a new PFA document, in which the final state of the cells and pools are used to define the {\PFAc cell} {\PFAc init} or {\PFAc pool} {\PFAc init} of the new document, such that a new scoring engine would start where the old one left off.  A PFA system may even re-use an old scoring engine as a new scoring engine (repeating phase 4 onward), but a re-used engine must behave exactly like a new engine with copied state, such that the re-use is an implementation detail and does not affect behavior.

A PFA system may call functions defined in the document's {\PFAc fcn} field at any time, but if the function modifies state (a {\PFAc cell-to} or {\PFAc pool-to} special form is reachable in its call graph) and the engine is not complete, the function call must not be allowed because it could affect the engine's behavior.  A PFA system must not execute {\PFAc begin}, {\PFAc action}, or {\PFAc end} outside of its lifecycle.

\hypertarget{hsec:method}{}
\subsection{Scoring method: map, emit, and fold}
\label{sec:method}

\hypertarget{hsec:input-output}{}
\subsection{Input and output type specification}
\label{sec:input-output}

data funnel (how input and output are handled)

\hypertarget{hsec:state}{}
\subsection{Persistent state: cells and pools}
\label{sec:state}

cells and pools (specification only: link to extraction and manipulation)

\hypertarget{hsec:concurrent}{}
\subsection{Concurrent access to shared state}
\label{sec:concurrent}

multiple engines

\hypertarget{hsec:exceptions}{}
\subsection{Exceptions}
\label{sec:exceptions}

\hypertarget{hsec:control}{}
\subsection{Execution control}
\label{sec:control}

overridable options

timeouts

\hypertarget{hsec:random}{}
\subsection{Pseudorandom number management}
\label{sec:random}

random numbers

\pagebreak

\section{Type system}

\hypertarget{hsec:avro-types}{}
\subsection{Avro types}
\label{sec:avro-types}

Orderless Avro schema reading


Type-safe null

\hypertarget{hsec:type-inference}{}
\subsection{Type inference}
\label{sec:type-inference}

\subsection{Type resolution, promotion, and covariance}

\subsection{Function parameter patterns}

\pagebreak

\section{Symbols, scope, and data structures}

garbage collector

\subsection{Immutable data, reassignable symbols}

\subsection{Expression-level scope and mutation restrictions}

\subsection{Data structure limitations}

No circular references

String-only map keys

\pagebreak

\section{User-defined functions}

\hypertarget{hsec:fcndef}{}
\label{form:fcndef}

\hypertarget{hsec:fcnref}{}
\label{form:fcnref}


\subsection{Syntax and scope}

\subsection{Anonymous callbacks and function references}

\pagebreak

\hypertarget{hsec:expressions}{}
\section{Expressions}
\label{sec:expressions}

Special forms and ordinary function calls

\subsection{Function calls}

\subsection{Symbol references}

\subsection{Literal values}

\subsection{Creating arrays, maps, and records}

\subsection{Symbol assignment and reassignment}

\subsection{Extracting from and updating arrays, maps, and records}

\subsection{Extracting from and updating cells and pools}

\subsection{Do blocks}

\subsection{Conditionals: if and cond}

\subsection{While loops: pretest and posttest}

\subsection{For loops: by index, array element, and key-value}

\subsection{Type-safe casting}

\subsection{Inline documentation}

\subsection{User-defined exceptions}

\subsection{Log messages}

\pagebreak

\section{Core library}

\subsection{Basic arithmetic}

\subsubsection{Addition of two values ($+$)}
\libfcn{+}

\subsubsection{Subtraction ($-$)}
\libfcn{-}

\subsubsection{Multiplication of two values (*)}
\libfcn{*}

\subsubsection{Floating-point division (/)}
\libfcn{/}

\subsubsection{Integer division (//)}
\libfcn{//}

\subsubsection{Negation (u$-$)}
\libfcn{u-}

\subsubsection{Modulo (\%)}
\libfcn{\%}

\subsubsection{Remainder (\%\%)}
\libfcn{\%\%}

\subsubsection{Raising to a power (**)}
\libfcn{**}

\subsection{Comparison operators}

Avro defines a \href{http://avro.apache.org/docs/1.7.6/spec.html#order}{sort order} for every pair of values with a compatible type, so any two objects of compatible type can be compared in PFA.

\subsubsection{General comparision (cmp)}
\libfcn{cmp}

\subsubsection{Equality (==)}
\libfcn{==}

\subsubsection{Inequality (!=)}
\libfcn{!=}

\subsubsection{Less than (<)}
\libfcn{<}

\subsubsection{Less than or equal to (<=)}
\libfcn{<=}

\subsubsection{Greater than (>)}
\libfcn{>}

\subsubsection{Greater than or equal to (>=)}
\libfcn{>=}

\subsubsection{Maximum of two values (max)}
\libfcn{max}

\subsubsection{Minimum of two values (min)}
\libfcn{min}

\subsection{Logical operators}

\subsubsection{Logical and (and)}
\libfcn{and}

\subsubsection{Logical or (or)}
\libfcn{or}

\subsubsection{Logical xor (xor)}
\libfcn{xor}

\subsubsection{Logical not (not)}
\libfcn{not}

\subsection{Bitwise arithmetic}

\subsubsection{Bitwise and (\&)}
\libfcn{\&}

\subsubsection{Bitwise or (|)}
\libfcn{|}

\subsubsection{Bitwise xor (\^{})}
\libfcn{\^{}}

\subsubsection{Bitwise not (\textasciitilde{})}
\libfcn{TILDE}

\pagebreak

\section{Math library}

\subsection{Constants}

Constants such as $\pi$ and $e$ are represented as stateless functions with no arguments.  Specific implementations may choose to replace the function call with its inline value.

\subsubsection{Archimedes' constant $\pi$ (m.pi)}
\libfcn{m.pi}

\subsubsection{Euler's constant $e$ (m.e)}
\libfcn{m.e}

\subsection{Common functions}

\subsubsection{Square root (m.sqrt)}
\libfcn{m.sqrt}

\subsubsection{Hypotnuse (m.hypot)}
\libfcn{m.hypot}

\subsubsection{Trigonometric sine (m.sin)}
\libfcn{m.sin}

\subsubsection{Trigonometric cosine (m.cos)}
\libfcn{m.cos}

\subsubsection{Trigonometric tangent (m.tan)}
\libfcn{m.tan}

\subsubsection{Inverse trigonometric sine (m.asin)}
\libfcn{m.asin}

\subsubsection{Inverse trigonometric cosine (m.acos)}
\libfcn{m.acos}

\subsubsection{Inverse trigonometric tangent (m.atan)}
\libfcn{m.atan}

\subsubsection{Robust inverse trigonometric tangent (m.atan2)}
\libfcn{m.atan2}

\subsubsection{Hyperbolic sine (m.sinh)}
\libfcn{m.sinh}

\subsubsection{Hyperbolic cosine (m.cosh)}
\libfcn{m.cosh}

\subsubsection{Hyperbolic tangent (m.tanh)}
\libfcn{m.tanh}

\subsubsection{Natural exponential (m.exp)}
\libfcn{m.exp}

\subsubsection{Natural exponential minus one (m.expm1)}
\libfcn{m.expm1}

\subsubsection{Natural logarithm (m.ln)}
\libfcn{m.ln}

\subsubsection{Logarithm base 10 (m.log10)}
\libfcn{m.log10}

\subsubsection{Arbitrary logarithm (m.log)}
\libfcn{m.log}

\subsubsection{Natural logarithm of one plus square (m.ln1p)}
\libfcn{m.ln1p}

\subsection{Rounding}

\subsubsection{Absolute value (m.abs)}
\libfcn{m.abs}

\subsubsection{Floor (m.floor)}
\libfcn{m.floor}

\subsubsection{Ceiling (m.ceil)}
\libfcn{m.ceil}

\subsubsection{Simple rounding (m.round)}
\libfcn{m.round}

\subsubsection{Unbiased rounding (m.rint)}
\libfcn{m.rint}

\subsubsection{Threshold function (m.signum)}
\libfcn{m.signum}

\subsubsection{Copy sign (m.copysign)}
\libfcn{m.copysign}

\subsection{Linear algebra}

including named row/col matrices

\pagebreak

\section{String manipulation}

Strings are immutable, so none of the following functions modifies a string in-place.  Some return a modified version of the original string.

\subsection{Basic access}

\subsubsection{Length (s.len)}
\libfcn{s.len}

\subsubsection{Extract substring (s.substr)}
\libfcn{s.substr}

\subsubsection{Modify substring (s.substrto)}
\libfcn{s.substrto}

\subsection{Search and replace}

\subsubsection{Contains (s.contains)}
\libfcn{s.contains}

\subsubsection{Count instances (s.count)}
\libfcn{s.count}

\subsubsection{Find first index (s.index)}
\libfcn{s.index}

\subsubsection{Find last index (s.rindex)}
\libfcn{s.rindex}

\subsubsection{Check start (s.startswith)}
\libfcn{s.startswith}

\subsubsection{Check end (s.endswith)}
\libfcn{s.endswith}

\subsection{Conversions to or from other types}

\subsubsection{Join an array of strings (s.join)}
\libfcn{s.join}

\subsubsection{Split into an array of strings (s.split)}
\libfcn{s.split}

\subsection{Conversions to or from other strings}

\subsubsection{Concatenate two strings (s.concat)}
\libfcn{s.concat}

\subsubsection{Repeat pattern (s.repeat)}
\libfcn{s.repeat}

\subsubsection{Lowercase (s.lower)}
\libfcn{s.lower}

\subsubsection{Uppercase (s.upper)}
\libfcn{s.upper}

\subsubsection{Left-strip (s.lstrip)}
\libfcn{s.lstrip}

\subsubsection{Right-strip (s.rstrip)}
\libfcn{s.rstrip}

\subsubsection{Strip both ends (s.strip)}
\libfcn{s.strip}

\subsubsection{Replace all matches (s.replaceall)}
\libfcn{s.replaceall}

\subsubsection{Replace first match (s.replacefirst)}
\libfcn{s.replacefirst}

\subsubsection{Replace last match (s.replacelast)}
\libfcn{s.replacelast}

\subsubsection{Translate characters (s.translate)}
\libfcn{s.translate}

\subsection{Regular Expressions}

and stemming

\pagebreak

\section{Array Manipulation}

\subsection{Basic access}

\subsubsection{Length (a.len)}
\libfcn{a.len}

\subsubsection{Extract subsequence (a.subseq)}
\libfcn{a.subseq}

\subsubsection{Modify subsequence (a.subseqto)}
\libfcn{a.subseqto}

\subsection{Search and replace}

\subsubsection{Contains (a.contains)}
\libfcn{a.contains}

\subsubsection{Count instances (a.count)}
\libfcn{a.count}

\subsubsection{Count instances by predicate (a.countPredicate)}
libfcn{a.countPredicate}

\subsubsection{Find first index (a.index)}
\libfcn{a.index}

\subsubsection{Find last index (a.rindex)}
\libfcn{a.rindex}

\subsubsection{Check start (a.startswith)}
\libfcn{a.startswith}

\subsubsection{Check end (a.endswith)}
\libfcn{a.endswith}

\subsection{Manipulation}

\subsubsection{Concatenate two arrays (a.concat)}
\libfcn{a.concat}

\subsubsection{Append (a.append)}
\libfcn{a.append}

\subsubsection{Insert or prepend (a.insert)}
\libfcn{a.insert}

\subsubsection{Replace item (a.replace)}
\libfcn{a.replace}

\subsubsection{Remove item (a.remove)}
\libfcn{a.remove}

\subsection{Reordering}

\subsubsection{Sort (a.sort)}
\libfcn{a.sort}

\subsubsection{Sort with a less-than function (a.sortLT)}
\libfcn{a.sortLT}

\subsubsection{Randomly shuffle array (a.shuffle)}
\libfcn{a.shuffle}

\subsubsection{Reverse order (a.reverse)}
\libfcn{a.reverse}

\subsection{Extreme values}

\subsubsection{Maximum of all values (a.max)}
\libfcn{a.max}

\subsubsection{Minimum of all values (a.min)}
\libfcn{a.min}

\subsubsection{Maximum with a less-than function (a.maxLT)}
\libfcn{a.maxLT}

\subsubsection{Minimum with a less-than function (a.minLT)}
\libfcn{a.minLT}

\subsubsection{Maximum $N$ items (a.maxN)}
\libfcn{a.maxN}

\subsubsection{Minimum $N$ items (a.minN)}
\libfcn{a.minN}

\subsubsection{Maximum $N$ with a less-than function (a.maxNLT)}
\libfcn{a.maxNLT}

\subsubsection{Minimum $N$ with a less-than function (a.minNLT)}
\libfcn{a.minNLT}

\subsubsection{Argument maximum (a.argmax)}
\libfcn{a.argmax}

\subsubsection{Argument minimum (a.argmin)}
\libfcn{a.argmin}

\subsubsection{Argument maximum with a less-than function (a.argmaxLT)}
\libfcn{a.argmaxLT}

\subsubsection{Argument minimum with a less-than function (a.argminLT)}
\libfcn{a.argminLT}

\subsubsection{Maximum $N$ arguments (a.argmaxN)}
\libfcn{a.argmaxN}

\subsubsection{Minimum $N$ arguments (a.argminN)}
\libfcn{a.argminN}

\subsubsection{Maximum $N$ arguments with a less-than function (a.argmaxNLT)}
\libfcn{a.argmaxNLT}

\subsubsection{Minimum $N$ arguments with a less-than function (a.argminNLT)}
\libfcn{a.argminNLT}

\subsection{Numerical combinations}

\subsubsection{Add all array values (a.sum)}
\libfcn{a.sum}

\subsubsection{Multiply all array values (a.product)}
\libfcn{a.product}

\subsubsection{Sum of logarithms (a.lnsum)}
\libfcn{a.lnsum}

\subsubsection{Arithmetic mean (a.mean)}
\libfcn{a.mean}

\subsubsection{Geometric mean (a.geomean)}
\libfcn{a.geomean}

\subsubsection{Median (a.median)}
\libfcn{a.median}

\subsubsection{Mode, or most common value (a.mode)}
\libfcn{a.mode}

\subsection{Set or set-like functions}

PFA does not have a set datatype, but arrays can be interpreted as sets with the following functions.

\subsubsection{Distinct items (a.distinct)}
\libfcn{a.distinct}

\subsubsection{Set equality (a.seteq)}
\libfcn{a.seteq}

\subsubsection{Union (a.union)}
\libfcn{a.union}

\subsubsection{Intersection (a.intersect)}
\libfcn{a.intersect}

\subsubsection{Set difference (a.diff)}
\libfcn{a.diff}

\subsubsection{Symmetric set difference (a.symdiff)}
\libfcn{a.symdiff}

\subsubsection{Subset check (a.subset)}
\libfcn{a.subset}

\subsubsection{Disjointness check (a.disjoint)}
\libfcn{a.disjoint}

\subsection{Functional programming}

\subsubsection{Map array items with function (a.map)}
\libfcn{a.map}

\subsubsection{Filter array items with function (a.filter)}
\libfcn{a.filter}

\subsubsection{Filter and map (a.filtermap)}
\libfcn{a.filtermap}

\subsubsection{Map and flatten (a.flatmap)}
\libfcn{a.flatmap}

\subsubsection{Reduce array items to a single value (a.reduce)}
\libfcn{a.reduce}

\subsubsection{Right-to-left reduce (a.reduceright)}
\libfcn{a.reduceright}

\subsubsection{Fold array items to another type (a.fold)}
\libfcn{a.fold}

\subsubsection{Right-to-left fold (a.foldright)}
\libfcn{a.foldright}

\subsubsection{Take items until predicate is false (a.takeWhile)}
\libfcn{a.takeWhile}

\subsubsection{Drop items until predicate is true (a.dropWhile)}
\libfcn{a.dropWhile}

\subsection{Functional tests}

\subsubsection{Existential check, $\exists$ (a.any)}
\libfcn{a.any}

\subsubsection{Univeral check, $\forall$ (a.all)}
\libfcn{a.all}

\subsubsection{Pairwise check of two arrays (a.corresponds)}
\libfcn{a.corresponds}

\subsection{Restructuring}

\subsubsection{Sliding window (a.slidingWindow)}
\libfcn{a.slidingWindow}

\subsubsection{Unique combinations of a fixed size (a.combinations)}
\libfcn{a.combinations}

\subsubsection{Permutations (a.permutations)}
\libfcn{a.permutations}

\subsubsection{Flatten array (a.flatten)}
\libfcn{a.flatten}

\subsubsection{Group items by category (a.groupby)}
\libfcn{a.groupby}

\pagebreak

\section{Manipulation of other data structures}

\subsection{Map}

\subsection{Record}

\subsection{Enum}

\subsection{Fixed}

\pagebreak

\section{Missing data handling}

\subsection{Impute library}

\subsubsection{Skip record (impute.errorOnNull)}
\libfcn{impute.errorOnNull}

\subsubsection{Replace with default (impute.defaultOnNull)}
\libfcn{impute.defaultOnNull}

\pagebreak

\section{Aggregation}

SQL-like functions

group-by tables

CUSUM

\pagebreak

\section{Descriptive statistics libraries}

\subsection{Sample statistics}

\subsubsection{Update aggregated mean (stat.sample.updateMean)}
\libfcn{stat.sample.updateMean}

\subsubsection{Compute aggregated mean (stat.sample.mean)}
\libfcn{stat.sample.mean}

accumulated mean, median(?)

\pagebreak

\section{Data mining models}

\subsection{Decision and regression Trees}

\subsubsection{Tree walk with simple predicates (model.tree.simpleWalk)}
\libfcn{model.tree.simpleWalk}

\subsubsection{Tree walk with user-defined predicates (model.tree.predicateWalk)}
\libfcn{model.tree.predicateWalk}

\subsection{Cluster models}

\subsection{Regression}

\subsection{Neural networks}

\subsection{Support vector machines}

\end{document}
