\documentclass{article}
\usepackage{fullpage}
\usepackage[]{hyperref}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{xcolor}
\usepackage{amsthm}
\usepackage{fancyvrb}
\usepackage{longtable}

\newcommand{\PFAc}{\ttfamily\bfseries}
\newcommand{\PFAp}{\ttfamily\bfseries}
\newcommand{\PFAt}{\ttfamily\bfseries}
\newcommand{\PFAtp}{\ttfamily\bfseries}
\newcommand{\PFApf}{\ttfamily\bfseries}
\newcommand{\PFAf}{\ttfamily\bfseries}

\newenvironment{description*}%
  {\vspace{-0.15 cm}\begin{description}%
    \setlength{\itemsep}{3pt}%
    \setlength{\parskip}{0pt}}%
  {\vspace{-0.25 cm}\end{description}}

\newenvironment{allowedfields}%
  {\begin{center} \begin{minipage}{0.9\linewidth} \begin{description}}%
  {\end{description} \end{minipage} \end{center}}

\hypersetup{colorlinks=true, allcolors=blue}

\theoremstyle{definition}
\newtheorem{example}{Example}[section]

\newenvironment{json}{
  \VerbatimEnvironment
  \begin{center}\begin{minipage}{0.9\linewidth}
  \begin{Verbatim}[formatcom=\ttfamily\bfseries]}{\end{Verbatim}\end{minipage}\end{center}}

\renewcommand{\arraystretch}{1.4}

\title{PFA: Portable Format for Analytics}
\author{Jim Pivarski}
\date{Sometime in 2014}

\input{libfcns}

\setlength{\parskip}{0.15 cm}
\begin{document}
\maketitle

{\large \bf Abstract}
\vspace{0.25 cm}

This specification defines the syntax and semantics of the Portable Format for Analytics (PFA).

PFA is a mini-language for mathematical calculations that is usually generated programmatically, rather than by hand.  A PFA document is a string of JSON-formatted text that describes an executable called a scoring engine.  Each engine has a well-defined input, a well-defined output, and functions for combining inputs to construct the output in an expression-centric syntax tree.  In addition, it has centralized facilities for maintaining state, with well-defined semantics for sharing state among scoring engines in a thread-safe way.  The specification defines a suite of mathematical and statistical functions for transforming data, but it does not define any means of communication with an operating system, file system, or network.  A PFA engine must be embedded in a larger system that has these capabilities, and thus an analytic workflow is decoupled into a part that manages data pipelines (such as Hadoop, Storm, or Akka), and a part that describes the algorithm to be performed on data (PFA).  

PFA is similar to the Predictive Model Markup Language (PMML), an XML-based specification for statistical models, but whereas PMML's focus is on statistical models in the abstract, PFA's focus is on the scoring procedure itself.  The same input given to two PFA-enabled systems must yield the same output, regardless of platform (e.g.\ a JVM in Hadoop, a client's web browser, a GPU kernel function, or even an IP core directly embedded in an integrated circuit).  Unlike PMML, the PFA specification defines the exact bit-for-bit behavior of any well-formed document, the semantics of data types and data structures, including behavior in concurrent systems, and all cases in which an exception should be thrown.  Like PMML, PFA is a specification, not an implementation, it defines a suite of statistical algorithms for analyzing data, and it is usually generated programmatically, as the output of a machine learning algorithm, for instance.

\vspace{0.5 cm}
{\large \bf Status of this document}
\vspace{0.25 cm}

{\it This section describes the status of this document at the time of the current draft.  Other documents may supersede this document.}

This document is an early draft that has not been endorsed for recommendation by any organization.  It describes a proposed specification that could, in the future, become a standard.

\pagebreak

\tableofcontents

\pagebreak

\section{Introduction}

\subsection{Motivation for PFA}

The Portable Format for Analytics (PFA) is a mini-language for mathematical calculations.  It differs from most programming languages in that it is optimized for automatic code generation, rather than writing programs by hand.  The primary use-case is to represent the output of machine learning algorithms, such that they can be freely moved between systems.  Traditionally, this field has been dominated by special-purpose file formats, each representing only one type of statistical model.  The Predictive Model Markup Language (PMML) provides a means of unifing the most common model types into one file format.  However, PMML can only express a fixed set of pre-defined model types; new model types must be agreed upon by the Data Mining Group (DMG) and integrated into a new version of PMML, then that new version must be adopted by the community before it is widely usable.

PFA represents models and analytic procedures more generally by providing generic programming constructs, such as conditionals, loops, persistent state, and callback functions, in addition to a basic suite of statistical tools.  Conventional models like regression, decision trees, and clustering are expressed by referencing the appropriate library function, just as in PMML, but new models can be expressed by composing library functions or passing user-defined callbacks.  Most new statistical techniques are variants of old techniques, so a small number of functions with the appropriate hooks for inserting user code can represent a wide variety of methods, many of which have not been discovered yet.

Given that flexibility is important, one might consider using a general purpose programming language, such as C, Java, Python, or especially R, which is specifically designed for statistics.  While this is often the easiest method for small problems that are explored, formulated, and solved on an analyst's computer, it is difficult to scale up to network-sized solutions or to deploy on production systems that need to be more carefully controlled than a personal laptop.  The special-purpose code may depend on libraries that cannot be deployed, or may even be hard to identify exhaustively.  In some cases, the custom code might be regarded as a stability or security threat that must be thoroughly reviewed before deployment.  If the analytic algorithm needs to be deployed multiple times before it is satisfactory and each deployment is reviewed for reasons unrelated to its analytic content, development would be delayed unnecessarily.  This problem is solved by decoupling the analytic workflow into a part that deals exclusively with mathematics (the PFA scoring engine) and the rest of the infrastructure (the PFA host).  A mathematical algorithm implemented in PFA can be updated frequently with minimal review, since PFA is incapable of raising most stability or security issues, due to its limited access.

PFA is restricted to the following operations: mathematical functions on numbers, strings, raw bytes, homogeneous lists, homogeneous maps (also known as hash-tables, associative arrays, or dictionaries), heterogeneous records, and unions of the above, where mathematical functions include basic operations, special functions, data sturcture manipulations, missing data handling, descriptive statistics, and common model types such as regression, decision trees, and clustering, parameterized for flexibility.  PFA does not include any means of accessing the operating system, the file system, or the network, so a rouge PFA engine cannot expose or manipulate data other than that which is intentionally funneled into it by the host system.  The full PFA specification allows recursion and unterminated loops, but execution time is limited by a timeout.  PFA documents may need to be reviewed for mathematical correctness, but they do not need to be reviewed for safety.

Another reason to use PFA as an intermediate model representation is for simplicity of code generation.  A machine learning algorithm generates an executable procedure, usually a simple, parameterized decider algorithm that categorizes or makes predictions based on new data.  Although the parameters might be encoded in a static file, some component must be executable.  A PFA document bundles the executable with its parameters, simplifying version control.

The syntax of PFA is better suited to automatic code generation than most programming languages.  Many languages have complex syntax to accomodate the way people think while programming, including infix operators, a distinction between statements and expressions, and in some cases even meaningful whitespace.  Though useful when writing programs by hand, these features only complicate automatic code generation.  A PFA document is an expression tree rendered in JSON, and trees are easy to programmatically compose into larger trees without introducing syntax errors in the generated code.  This is well-known in the Lisp community, since the ease of writing code-modifying macros in Lisp is often credited to its exclusive use of expression trees, rendered as parenthesized lists (known as S-expressions).  PFA uses JSON, rather than S-expressions, because libraries for manipulating JSON objects are more widely available and JSON provides a convenient syntax for maps, but the transliteration between JSON and S-expressions is straight-forward.

Another benefit of PFA's simplicity relative to general programming languages is that it is more amenable to static analysis.  A PFA host can more thoroughly examine an incoming PFA document for undesirable features.  Although PFA makes use of callback functions to provide generic algorithms, functions are not first-class objects in the language, meaning that they cannot be dynamically assigned to variables.  The identity of every function call can be determined without running the engine, which makes it possible to statically generate a graph of function calls and identify recursive loops.  In very limited runtime environments, such as some GPUs, the compiler implicitly inlines all function calls, so recursion is not possible.  In cases like these, static analysis of the PFA document is a necessary step in generating the executable.

A PFA document can also be statically type-checked.  This allows for faster execution times, since types do not need to be checked at run-time, but it also provides additional safety to the PFA host.

PFA uses Apache Avro schemae for type annotations.  Avro is an open-source serialization protocol, widely used in Hadoop and related projects, whose type schemae are expressed as JSON objects and whose data structures can be expressed as JSON objects.  Therefore, all parts of the PFA engine, including control structures, type annotations, and embedded data are all expressed in one seamless JSON object.  Avro additionally has well-defined rules to resolve different but possibly compatible schemae, which PFA reinterprets as type promotion (allowing integers to be passed to a function that expects floating-point numbers, for instance).  When interpreted this way, Avro also has a type-safe null, which PFA uses to ensure that missing data are always explicitly handled.  Finally, the input and output of every PFA engine can always be readily (de)serialized into Avro's binary format or JSON representation, since Avro libraries are available on a wide variety of platforms.

\subsection{Terminology used in this specification}

Within this specification, the key words ``MUST'', ``MUST NOT'', ``REQUIRED'', ``SHALL'', ``SHALL NOT'', ``SHOULD'', ``SHOULD NOT'', ``RECOMMENDED'', ``MAY'', and ``OPTIONAL'' are to be interpreted as described in RFC 2119 (see \href{http://www.ietf.org/rfc/rfc2119.txt}{RFC2119}).  However, for readability, these words do not appear in all uppercase letters in this specification.

At times, this specification provides hints and suggestions for implementation.  These suggestions are not normative and conformance with this specification does not depend on their realization.  These hints contain the expression ``We suggest\ldots'', ``Specific implementations may\ldots'', or similar wording.

This specification uses the terms ``JSON object'', ``JSON object member name'', ``JSON object member value'', ``JSON array'', ``JSON array value'', ``number'', ``integer'', ``string'', ``boolean'', and ``null'' as defined in the JSON specification (\href{http://tools.ietf.org/html/rfc4627}{RFC-4627}), sections 2.2 through 2.5.  It also references and quotes sections of the Avro 1.7.6 specification (\url{http://avro.apache.org/docs/1.7.6/spec.html}).

\subsection{PFA MIME type and file name extension}

The recommended MIME type for PFA is ``application/pfa+json'', though this is not yet in the process of standardization.

It is recommended that PFA files have the extension ``.pfa'' (all lowercase) on all platforms.  It is recommended that gzip-compressed PFA files have the extension ``.pfaz'' (all lowercase) on all platforms.

\hypertarget{hsec:conformance}{}
\subsection{Levels of PFA conformance and PFA subsets}
\label{sec:conformance}

PFA is a large specification with many modules, so some projects or vendors may wish to implement some but not all of the specification.  However, interoperability is the reason PFA exists; if an implementation does not adhere to the standard, it has limited value.  It is therefore useful to explicitly define what it means for a system to partially implement the standard.

JSON subtrees of a PFA document are interpreted in the following six contexts.
\begin{itemize}
\item Top-level fields are JSON object member name, value pairs in the outermost JSON object of the PFA document.  They have unique member names and describe global aspects of the scoring engine.
\item Special forms are JSON objects that specify executable expressions and function definitions.  Each is associated with a unique name.
\item Library functions are strings that specify routines not defined in the PFA document itself.  Each is associated with a unique name that does not conflict with any of the special forms' names.
\item Avro type schemae are JSON objects and strings that describe data types.  The syntax and meaning of Avro types are specified in \href{http://avro.apache.org/docs/1.7.6/spec.html}{the Avro 1.7.6 specification}.
\item Embedded data are JSON objects, JSON arrays, numbers, integers, strings, booleans, and nulls that describe data structures.  The syntax and meaning of these objects are also defined by Avro, as the format used by the {\PFAc JSONEncoder} and {\PFAc JSONDecoder}.
\item Options are JSON object member values of the {\PFAc options} top-level field and may be overridden by the PFA system.  They all have well-defined defaults and unique, hierarchical names.
\end{itemize}

A system may be partially PFA compliant if it implements some but not all top-level fields, some but not all special forms, or some but not all library functions.  Its coverage may be specified by listing the object member names of the top-level fields that it does implement, the names of the special forms that it does implement, and the names of the library functions that it does implement.  Those top-level fields, special forms, and library functions that it does implement must be completely and correctly implemented.  The coverage is therefore atomic and one can immediately determine if a particular system can execute a particular PFA document by checking the set of names used by the document against the set of names implemented by the system.

Some special forms and library functions make use of some top-level fields.  For example, library functions that generate random numbers use the {\PFAc randseed} field for configuration.  These special forms and library functions cannot be considered implemented unless the corresponding top-level fields are also implemented.  The dependencies are explicitly defined in this specification.

Avro type schemae and JSON-encoded data should be completely implemented, to the extent defined by the Avro specification.  We suggest that implementations use language-specific Avro libraries as much as possible, rather than implementing Avro-related features in a PFA system.

Options may also be implemented atomically by name.  If a named option is not implemented, the system should behave as though that option had its default value, regardless of whether the option is explicitly set in the PFA document.  Options can in general be overridden by a host system, so if a host system doesn't implement an option, it is as though the system enforces the default.

The PFA standard is defined so that a PFA-compliant system can verify that the JSON types of a PFA document are correctly composed (syntax check), verify that the PFA invariants are maintained and Avro data types are correctly composed (semantic check), and impose additional constraints on the set of top-level fields, special forms, and library functions used (optional checks).  A PFA-compliant system should perform the syntax and semantic checks, including all type inference and type checking, though it is not strictly required.  A PFA document that does not satisfy these invariants and type constraints is not valid and its behavior is not defined by this specification.  The third set of checks, however, is completely optional and different systems may apply different constraints on the kinds of scoring engines they are willing to execute.  For instance, an implementation targeting a limited environment in which recursion is not possible may analyze the document and reject it if any recursive loops are found.

This specification does not define any standardized subsets of PFA.  As stated above, partial conformance is defined by ad hoc subsets of atomic units.  However, as experience develops, the community may define industry-standard subsets of PFA for specific purposes or special environments.  Conforming to a standardized subset would provide better interoperability than defining ad hoc subsets, and we would recommend such a standard when it exists.  At present, we can only recommend a carefully chosen ad hoc subset or complete conformance.

\pagebreak

\section{PFA document structure}

A PFA document is a serialized JSON object representing an executable scoring engine.  Only the following JSON object member names may appear at this JSON nesting level.  These are the top-level fields referred to in the \hyperlink{hsec:conformance}{conformance section} of this specification.  Three fields, {\PFAc action}, {\PFAc input}, and {\PFAc output}, are required for every PFA document and are therefore required for every PFA implementation.  The rest are optional for PFA documents and not strictly required for PFA implementations.  As explained in the conformance section, not implementing some top-level fields can make some special forms and functions unimplementable.

\begin{allowedfields}
\item[\PFAc name:] A string used to identify the scoring engine (has no effect on calculations).
\item[\PFAc method:] A string that may be ``map'', ``emit'', or ``fold'' (\hyperlink{hsec:method}{see Sec.~\ref{sec:method}}).  If absent, the default value is ``map''.
\item[\PFAc input:] An Avro schema representing the data type of data provided to the scoring engine (\hyperlink{hsec:input-output}{see Sec.~\ref{sec:input-output}}).
\item[\PFAc output:] An Avro schema representing the data type of data produced by the scoring engine (\hyperlink{hsec:input-output}{see Sec.~\ref{sec:input-output}}).  The way that output is returned to the host system depends on the {\PFAc method}.
\item[\PFAc begin:] An \hyperlink{hsec:expressions}{expression} or JSON array of \hyperlink{hsec:expressions}{expressions} that are executed in the begin phase of the scoring engine's run (\hyperlink{hsec:phases}{see Sec.~\ref{sec:phases}}).
\item[\PFAc action:] An \hyperlink{hsec:expressions}{expression} or JSON array of \hyperlink{hsec:expressions}{expressions} that are executed for each input datum in the active phase of the scoring engine's run (\hyperlink{hsec:phases}{see Sec.~\ref{sec:phases}}).
\item[\PFAc end:] An \hyperlink{hsec:expressions}{expression} or JSON array of \hyperlink{hsec:expressions}{expressions} that are executed in the end phase of the scoring engine's run (\hyperlink{hsec:phases}{see Sec.~\ref{sec:phases}}).
\item[\PFAc fcns:] A JSON object whose member values are \hyperlink{hsec:fcndef}{function definitions}, defining routines that may be called by expressions in {\PFAc begin}, {\PFAc action}, {\PFAc end}, or by expressions in other functions.
\item[\PFAc zero:] Embedded JSON data whose type must match the {\PFAc output} type of the engine.  This is only used by the ``fold'' method to initialize the fold aggregation.  If {\PFAc method} is ``map'' or ``emit'', this field is ignored.
\item[\PFAc cells:] A JSON object whose member values specify statically allocated, named, typed units of persistent state or embedded data (\hyperlink{hsec:state}{see Sec.~\ref{sec:state}}).  The format of this JSON object is restricted: \hyperlink{hsec:cells-pools}{see Sec.~\ref{sec:cells-pools}}.
\item[\PFAc pools:] A JSON object whose member values specify dynamically allocated namespaces of typed persistent state (\hyperlink{hsec:state}{see Sec.~\ref{sec:state}}).  The format of this JSON object is restricted: \hyperlink{hsec:cells-pools}{see Sec.~\ref{sec:cells-pools}}.
\item[\PFAc randseed:] An integer which, if present, sets the seed for pseudorandom number generation (\hyperlink{hsec:method}{see Sec.~\ref{sec:random}}).
\item[\PFAc doc:] A string used to describe the scoring engine or its provenance (has no effect on calculations).
\item[\PFAc metadata:] A JSON object, array, string, number, boolean, or null used to describe the scoring engine or its provenance (has no effect on calculations).
\item[\PFAc options:] A JSON object of JSON objects, arrays, strings, numbers, booleans, or nulls used to control execution.  The set of possible options and their representation is restricted:: see \hyperlink{hsec:options}{see Sec.~\ref{sec:options}}.
\end{allowedfields}

\noindent \begin{minipage}{\linewidth}
\begin{example}
This is the simplest possible PFA document.  It only reads {\PFAc null} values, returns {\PFAc null} values, and performs no calculations.
\begin{json}
{"input": "null", "output": "null", "action": null}
\end{json}
\end{example}
\end{minipage}

\begin{example}
This is a simple yet non-degenerate PFA document.  It increments numerical input by 1.
\begin{json}
{"input": "double", "output": "double", "action": {"+": ["input", 1]}}
\end{json}
\end{example}

\begin{example}
This example implements a small decision tree.  Input data are records with three fields: ``one'' (integer), ``two'' (double), and ``three'' (string).  The decision tree is stored in a cell named ``tree'' with type ``TreeNode''.  The tree has three binary splits (four leaves).  The scoring engine walks from the root to a leaf for each input datum, choosing a path based on values found in the record's fields, and returns the string it finds at the tree's leaf.  (See the definition of the \hyperlink{model.tree.simpleWalk}{model.tree.simpleWalk} function.)
\begin{json}
{"input": {"type": "record", "name": "Datum", "fields":
   [{"name": "one", "type": "int"},
    {"name": "two", "type": "double"},
    {"name": "three", "type": "string"}]},
 "output": "string",
 "cells": {"tree":
             {"type":
               {"type": "record",
                "name": "TreeNode",
                "fields": [
                  {"name": "field", "type": "string"},
                  {"name": "operator", "type": "string"},
                  {"name": "value", "type": ["double", "string"]},
                  {"name": "pass", "type": ["string", "TreeNode"]},
                  {"name": "fail", "type": ["string", "TreeNode"]}]},
              "init":
                {"field": "one",
                 "operator": "<",
                 "value": {"double": 12},
                 "pass":
                   {"TreeNode":
                     {"field": "two",
                      "operator": ">",
                      "value": {"double": 3.5},
                      "pass": {"string": "yes-yes"},
                      "fail": {"string": "yes-no"}}},
                 "fail":
                   {"TreeNode":
                     {"field": "three",
                      "operator": "==",
                      "value": {"string": "TEST"},
                      "pass": {"string": "no-yes"},
                      "fail": {"string": "no-no"}}}}}},
 "action":
   {"model.tree.simpleWalk": ["input", {"cell": "tree"}]}}
\end{json}
\end{example}

\hypertarget{hsec:cells-pools}{}
\subsection{Cells and Pools}
\label{sec:cells-pools}

The {\PFAc cells} and {\PFAc pools} top-level fields, if present, are JSON objects whose member values are cell-specifications or pool-specifications, respectively.  A cell is a mutable, global data store that holds a single value with a specific type, and a pool is a mutable map from dynamically allocated names to values of a specific type (\hyperlink{hsec:state}{see Sec.~\ref{sec:state}}).

A cell-specification is a JSON object with the following fields.
\begin{allowedfields}
\item[\PFAc type:] {\it (required)} An Avro schema representing the data type of this cell.
\item[\PFAc init:] {\it (required)} Embedded JSON whose type must match {\PFAc type}.  This is the initial value of the cell (or constant value if it is never modified).
\item[\PFAc shared:] An optional boolean specifying whether this cell is thread-local to one scoring engine or shared among a battery of similar engines (\hyperlink{hsec:concurrent}{see Sec.~\ref{sec:concurrent}}).  The default is {\PFAc false}.
\item[\PFAc rollback:] An optional boolean specifying whether this cell should be rolled back to the state it had at the beginning of an {\PFAc action} if an \hyperlink{hsec:exceptions}{exception} occurs during the {\PFAc action}.  The default is {\PFAc false}, and {\PFAc shared} and {\PFAc rollback} are mututally incompatible: they cannot both be {\PFAc true}.
\end{allowedfields}

A pool-specification is a JSON object with the following fields.
\begin{allowedfields}
\item[\PFAc type:] {\it (required)} An Avro schema representing the data type of this pool.
\item[\PFAc init:] JSON object whose member values are embedded JSON that must match {\PFAc type}.  Unlike a cell, a pool may be empty on initialization, in which case {\PFAc init} is either unspecified or {\PFAc \{\}}.
\item[\PFAc shared:] An optional boolean specifying whether this pool is thread-local to one scoring engine or shared among a battery of similar engines (\hyperlink{hsec:concurrent}{see Sec.~\ref{sec:concurrent}}).  The default is {\PFAc false}.
\item[\PFAc rollback:] An optional boolean specifying whether this pool should be rolled back to the state it had at the beginning of an {\PFAc action} if an \hyperlink{hsec:exceptions}{exception} occurs during the {\PFAc action}.  The default is {\PFAc false}, and {\PFAc shared} and {\PFAc rollback} are mututally incompatible: they cannot both be {\PFAc true}.
\end{allowedfields}

A complete explanation of cells and pools is given in \hyperlink{hsec:state}{Sec.~\ref{sec:state}}.

\pagebreak

\section{Scoring engine execution model}

A PFA document (string of JSON-formatted text) describes a PFA scoring engine (executable routine) or a battery of initially identical engines.  An engine behaves as a single-threaded executable with global state (cells and pools) and local variables.  A battery of scoring engines may run in parallel and only share data if some cells or pools are explicitly marked as {\PFAc shared}.  Although a battery of scoring engines generated by a single PFA document start in exactly the same state, they may evolve into different states if they have any unshared cells or pools.

PFA engines are units of work that may fit into a pipeline system like Hadoop, Storm, or Akka.  In a map-reduce framework such as Hadoop, for instance, one PFA document could describe the calculation performed by all of the mappers and another could describe the calculation performed by all of the reducers.  The mappers are a battery of independent PFA engines, as are the reducers.  In pure map-reduce, the mappers would not communicate with each other and the reducers would not communicate with each other, so none of the cells or pools should be marked as {\PFAc shared}.  With this separation of concerns, issues of transferring data, interpreting input file types, and formatting output should be handled by the pipeline system (Hadoop in this case) while the mathematical procedure is handled by PFA.  Changing file formats would require an update to the pipeline code (and possibly a code review), but changing details of the analytic would only require a new PFA document (a JSON configuration file).

\hypertarget{hsec:phases}{}
\subsection{Execution phases of a PFA scoring engine}
\label{sec:phases}

A PFA engine has a 7 phase lifecycle.  These phases are the following, executed in this order:

\begin{enumerate}
\item reading the PFA document and performing a syntax check;
\item verifying PFA invariants and checking type consistency;
\item additional checks, constraints required by a particular PFA system;
\item initialization of the engine;
\item execution of the {\PFAc begin} routine;
\item execution of the {\PFAc action} routine for each input datum;
\item execution of the {\PFAc end} routine.
\end{enumerate}

In phase 1, JSON is decoded and may be used to build an abstract syntax tree of the whole document.  At this stage, JSON types must be correctly matched (e.g.\ if a number is expected, a string cannot be provided instead) to build the syntax tree.  Incorrectly formatted JSON should also be rejected, though we recommend that a dedicated JSON decoder is used for this task.  Avro schemae should also be interpreted in this phase (see \hyperlink{hsec:avro-types}{Sec.~\ref{sec:avro-types}}).

In phase 2, the loaded PFA document is interpreted as an executable.  If the specific PFA implementation builds code with macros, compiles bytecode, or synthesizes a circuit for execution, that work should happen in this phase.  Data types should be inferred and checked (see \hyperlink{hsec:type-inference}{Sec.~\ref{sec:type-inference}}), especially if the executable is compiled.

Phase 3 is provided for optional checks.  Due to limitations of a particular environment, some PFA systems may need to be more restrictive than the general specification and reject what would otherwise be a valid PFA document.  Reasons include unimplemented function calls, inability to implement recursion, or data structures that are too large.  The phase 3 checks may need to be performed concurrently with the phase 2 checks to build the executable.

Phase 4, initialization, is when data structures such as cells and pools are allocated and filled, network connections are established (if relevant for a particular PFA implementation), pseudorandom number generators are seeded, etc.  These are actions that the engine must perform to work properly but are not a part of the {\PFAc begin}, {\PFAc action}, or {\PFAc end} routines.

The actions performed in the last three phases, {\PFAc begin}, {\PFAc action}, and {\PFAc end}, are explicitly defined in the PFA document.  A PFA system must implement the {\PFAc action} phase, since every PFA document must define an {\PFAc action}.  The {\PFAc action} accepts input and returns output, though the way it does so depends on the {\PFAc method} (\hyperlink{hsec:method}{Sec.~\ref{sec:method}}).

The {\PFAc begin} and {\PFAc end} phases do not accept input and do not return output: they can only modify cells and pools, emit log messages, or throw exceptions.  A PFA system is not required to implement {\PFAc begin} and {\PFAc end}.  If a system that does not implement {\PFAc begin} encounters a document that has a {\PFAc begin} routine, it must fail with an error.  If a system that does not implement {\PFAc end} encounters a document that has an {\PFAc end} routine, it need not fail with an error, though it may.  This is because some PFA documents may use {\PFAc begin} to initialize essential data structures and the {\PFAc action} would only function properly if {\PFAc begin} has been executed, but the {\PFAc end} routine can only affect the state of a completed scoring engine whose interpretation is implementation-specific.  Moreover, some data pipelines do not even have a concept of completion, such as Storm.

After all input data have been passed to the scoring engine and the last {\PFAc action} or {\PFAc end} routine has finished, the scoring engine is said to be completed.  This may be considered an eighth phase of the engine, though its behavior at this point is not defined by this specification.  A particular PFA system may extract aggregated results from a completed engine's state and it may even call functions defined in the document's {\PFAc fcn} field, but this is beyond the scope of the standard PFA lifecycle.  (Note: if the primary purpose of a scoring engine is to aggregate data, consider using the ``fold'' {\PFAc method} instead of extracting from the engine's internal state.)

A completed scoring engine may be used to create a new PFA document, in which the final state of the cells and pools are used to define the {\PFAc cell} {\PFAc init} or {\PFAc pool} {\PFAc init} of the new document, such that a new scoring engine would start where the old one left off.  A PFA system may even re-use an old scoring engine as a new scoring engine (repeating phase 4 onward), but a re-used engine must behave exactly like a new engine with copied state, such that the re-use is an implementation detail and does not affect behavior.

A PFA system may call functions defined in the document's {\PFAc fcn} field at any time, but if the function modifies state (a ``cell-to'' or ``pool-to'' special form is reachable in its call graph) and the engine is not complete, the function call must not be allowed because it could affect the engine's behavior.  A PFA system must not execute {\PFAc begin}, {\PFAc action}, or {\PFAc end} outside of its lifecycle.

\hypertarget{hsec:method}{}
\subsection{Scoring method: map, emit, and fold}
\label{sec:method}

PFA defines the following three methods for calling the {\PFAc action} routine of a scoring engine.
\begin{allowedfields}
\item[``map'':] The {\PFAc action} routine is given an {\PFAc input} value, which it uses to construct and return an output.  Barring \hyperlink{hsec:exceptions}{exceptions}, the output dataset would have exactly as many values as the input dataset.
\end{allowedfields}
\begin{allowedfields}
\item[``emit'':] The {\PFAc action} routine is given an {\PFAc input} value and an {\PFAc emit} callback function, and the functional return value is ignored.  The scoring engine returns results to the host system by calling {\PFAc emit}.  It can call {\PFAc emit} any number of times, and thus the output dataset may be smaller or larger than the input dataset.  For example, a filter would call {\PFAc emit} zero or one times for each input.
\end{allowedfields}
\begin{allowedfields}
\item[``fold'':] The {\PFAc action} routine is given an {\PFAc input} value and a {\PFAc tally} value, which it uses to construct and return an output.  The first time {\PFAc action} is invoked, {\PFAc tally} is equal to {\PFAc zero} (the top-level field).  On the $N^{\mbox{\scriptsize th}}$ time {\PFAc action} is invoked, {\PFAc tally} is equal to the $(N - 1)^{\mbox{\scriptsize th}}$ return value.  Thus, a ``fold'' scoring engine is an aggregator: transformed inputs may be counted, summed, maximized, or otherwise accumulated in the {\PFAc tally}.  The aggregate of the entire input dataset is the last return value of {\PFAc action}, though the host system may make use of partial sums as well.
\end{allowedfields}

For all three methods, the {\PFAc input} is available to expressions as a read-only symbol that can be accessed in an expression as the JSON string {\PFAc "input"} (see \hyperlink{hsec:symbol-ref}{Sec.~\ref{sec:symbol-ref}}).  The {\PFAc input} symbol's scope is limited to the {\PFAc action} routine: it is not accessible in user-defined functions unless explicitly passed.  The {\PFAc input} symbol's data type is specified by the top-level field named {\PFAc input}.

For the ``map'' and ``fold'' methods, the data type of the last expression in the {\PFAc action} routine must be the type specified by the top-level field named {\PFAc output}.  For the ``emit'' method, there is no constraint on the type of the last expression in {\PFAc action}, but the argument passed to the {\PFAc emit} function must have {\PFAc output} type.

For the ``emit'' method, the {\PFAc emit} function is a globally accessible function.  It may be \hyperlink{hsec:function-call}{called} or \hyperlink{hsec:fcnref}{referenced} without qualification by any user-defined function or even in the {\PFAc begin} and {\PFAc end} routines.

For the ``fold'' method, the {\PFAc tally} is available to expressions as a read-only symbol that can be accessed in an expression as the JSON string {\PFAc "tally"} (see \hyperlink{hsec:symbol-ref}{Sec.~\ref{sec:symbol-ref}}).  The {\PFAc tally} symbol's scope is limited to the {\PFAc action} routine: it is not accessible in user-defined functions unless explicitly passed.  The {\PFAc tally} symbol's data type is specified by the {\PFAc output} top-level field.  The top-level field named {\PFAc zero} must also have {\PFAc output} type.

The means by which input values are provided to the scoring engine, output values are retrieved, and the {\PFAc emit} function is set or changed are all unspecified.  A PFA system may change the {\PFAc emit} function at any time, even while an {\PFAc action} is being processed (though we do not recommend this).  However, the {\PFAc emit} function must be defined and callable at all times during the {\PFAc begin}, {\PFAc action}, and {\PFAc end} phases of the scoring engine's lifecycle.

\hypertarget{hsec:input-output}{}
\subsection{Input and output type specification}
\label{sec:input-output}

The member values of the top-level fields {\PFAc input} and {\PFAc output} are Avro schemae (see \hyperlink{hsec:avro-types}{Sec.~\ref{sec:avro-types}}).  The way that these types constrain the input and output of scoring engines depends on the {\PFAc method} and is described in \hyperlink{hsec:method}{Sec.~\ref{sec:method}}.

The input data provided to the scoring engine must conform to the {\PFAc input} type in the sense that there must be an unambiguous way to generate it from Avro-encoded data, though this conversion need not actually take place.  For example, if the {\PFAc input} is {\PFAc \{"type":$\!$ "array", "items":$\!$ "int"\}}, then the values passed to the scoring engine must be ordered lists of integers, though they may be implemented as arrays, linked lists, immutable vectors, or any other functionally equivalent data structure that the PFA implementation is capable of using in calculations.  The data source need not be Avro-encoded; the Avro schema is only used to specify the type, not to perform conversions.  Similarly, the output data must conform to the {\PFAc output} type in the sense that there must be an unambiguous way to convert it to Avro-encoded data, though this conversion need not actually take place.

Given that the input and output types are described by Avro schemae, the Avro binary and JSON data formats would be particularly convenient ways to read and write data.  However, there is no requirement that a PFA system should have this capability.  Data conversion and internal data format are both outside the scope of the PFA specification.

\hypertarget{hsec:state}{}
\subsection{Persistent state: cells and pools}
\label{sec:state}

PFA defines two mechanisms to maintain state: cells and pools.  Cells are global variables with a fixed name and type that must be initialized before the scoring engine's run begins.  A cell's value can change to a new value of the same type, but the cell cannot be deleted and new cells cannot be created during the scoring engine's run.  Pools are global namespaces with a fixed type.  New named values can be created within a pool at runtime, as long as they have the correct type, and old values can be deleted at runtime.

A pool of type ``{\PFAtp X}'' would be equivalent to a cell whose type is ``map of {\PFAtp X}'' execpt for performance and concurrency issues.  All special forms and library functions in the PFA specification treat data structures as immutable objects (\hyperlink{hsec:immutable}{see Sec.~\ref{sec:immutable}}), but scoring engines often need to maintain very large key-value tables.  If pools were not available, a PFA implementation would either incur a performance penalty if it maintained a large map in a cell as an immutable object or if it maintained all temporary variables as mutable objects.  With both cells and pools, a PFA implementation may maintain all values as immutable objects, including cells, and maintain pools as mutable maps of immutable objects.  \hyperlink{hsec:concurrent}{See Sec.~\ref{sec:concurrent}} for a discussion of concurrency issues in cells and pools.

Cells can only be accessed through the ``cell'' special form and can only be modified through the ``cell-to'' special form.  Pools can only be accessed through the ``pool'' special form and modified through the ``pool-to'' special form (\hyperlink{hsec:cell-pool-forms}{see Sec.~\ref{sec:cell-pool-forms}}).

One common use of persistent state is to represent a complex statistical model, such as a large decision tree.  In most cases, such a model is constant during the scoring engine's run, and this constraint may be enforced through static analysis if the model is stored in a cell.  Another common use is to represent recent or accumulated data in a table, indexed by key.  In most cases, this table is updated frequently and new table entries may be added at any time.  Furthermore, it is often useful to distribute the table-fill operation among a battery of concurrent scoring engines, with different engines modifying different keys at the same time.  These cases are more easily implemented as pools or shared pools.

\hypertarget{hsec:concurrent}{}
\subsection{Concurrent access to shared state}
\label{sec:concurrent}

If the {\PFAc shared} member of a cell or pool's specification is {\PFAc true}, the cell or pool is not assumed to be thread-local (\hyperlink{hsec:cells-pools}{see Sec.~\ref{sec:cells-pools}}).  It may be shared among a battery of identical scoring engines in a multi-threaded process, shared among identical scoring engines distributed across a network, shared in a database among different types of processes, or shared among components of an integrated circuit, etc.  In any case, some rules must be followed to avoid simultaneous attempts to modify the data, and these rules must be standardized to ensure that the same scoring engine has the same behavior on different systems.

Shared cells and pools in PFA follow a read-copy-update rule for concurrent access: attempts to read the shared resource (through the ``cell'' or ``pool'' special forms) always succeed without blocking and attempts to write (through the ``cell-to'' or ``pool-to'' special forms) lock the resource or wait until another writer's lock is released.  The writers must operate on a copy of the cell or pool's data (or on immutable data) so that readers can access the old version during the update process.  The new value must be updated atomically at the end of the update process.

Although an update operation may only modify a part of the cell's structure (one value in an array, for instance), the granularity of the writers' lock is the entire cell: two writers must not be able to modify different parts of the same cell at the same time.  The granularity of the writers' lock on pools is limited to a single named entity within the pool: two writers must be able to modify different entities in the pool at the same time, but not different parts of the same named entity.

The ``cell-to'' and ``pool-to'' special forms accept user-defined update functions (\hyperlink{hsec:cell-pool-forms}{see Sec.~\ref{sec:cell-pool-forms}}) but these functions must not directly or indirectly call ``cell-to'' or ``pool-to'' because such a situation could lead to deadlock.  This rule can be enforced by examining the call graph.

\hypertarget{hsec:exceptions}{}
\subsection{Exceptions}
\label{sec:exceptions}

As much as is reasonably possible, PFA documents can be statically analyzed to avoid errors at runtime.  However, some error states cannot be predicted without runtime information.  These error states and their exact messages are explicitly defined for each susceptible special form and library function.  If the specified error conditions are met in the {\PFAc begin} routine of a scoring engine, processing stops and should not continue to the {\PFAc action} routine.  If error conditions occur when the {\PFAc action} routine is processing an input datum, processing of that datum stops and may either continue to the next datum or stop the scoring engine entirely.  The PFA host may choose to stop or continue on the basis of the standardized error message.  If error conditions occur in the {\PFAc end} routine, processing stops.

This abrupt end of processing may occur deep in an \hyperlink{hsec:expressions}{expression} or array of \hyperlink{hsec:expressions}{expressions} and behaves like an exception: control flow exits the routine immediately upon encountering the error condition and is either caught by the host system or it halts the process.  In environments where this is difficult to implement, control flow may continue to the end of the routine, but side-effects such as modifications to persistent state and \hyperlink{hsec:logs}{log messages} must be avoided.

If the host system catches an exception in {\PFAc action} and continues to the next datum, and if a cell or pool's {\PFAc rollback} member is {\PFAc true}, then that cell or pool should be reverted to the value that it had at the beginning of the {\PFAc action} (\hyperlink{hsec:cells-pools}{see Sec.~\ref{sec:cells-pools}}).  If the {\PFAc rollback} member is absent or {\PFAc false}, then the cell or pool's value at the start of the next {\PFAc action} should be the value it had at the time of the exception.

In addition to exceptions raised by special forms and library functions, a PFA document can raise custom exceptions with the ``error'' special form (\hyperlink{hsec:exception-form}{see Sec.~\ref{sec:exception-form}}).  The rules described above apply equally to custom exceptions, though we recommend that PFA systems differentiate between built-in exceptions (whose error messages are explicitly defined by this specification) and custom exceptions (whose error messages are free-form).

If a {\PFAc timeout} is defined in the PFA document's {\PFAc options} or is imposed by the PFA system, a {\PFAc begin}, {\PFAc action}, or {\PFAc end} routine that exceeds this timeout raises an exception with the message ``exceeded timeout of $N$ milliseconds'' where $N$ is the relevant timeout.  Timeout exceptions follow the same rules as built-in and custom exceptions.

If possible in a given system, no exceptions other than PFA exceptions should ever be raised while executing a {\PFAc begin}, {\PFAc action}, or {\PFAc end} routine.

\hypertarget{hsec:options}{}
\subsection{Execution options}
\label{sec:options}

The {\PFAc options} top-level field allows PFA documents to request that they are executed in a particular way.  However, the PFA system may override any of these options with its own values, or with the defaults.  When overriding an option, the PFA system should somehow indicate that this is the case, possibly through a log message.

The complete set of options, their JSON types, and their default values are given below.  If a PFA document attempts to set an option that is not in this list or attempts to set an option with the wrong type, it is a semantic error (phase 2 in \hyperlink{hsec:phases}{see Sec.~\ref{sec:phases}}) and the scoring engine should not be started.

\noindent\begin{longtable}{p{0.23\linewidth} p{0.12\linewidth} p{0.14\linewidth} p{0.4\linewidth}}
{\bf Option name} & {\bf JSON type} & {\bf Default value} & {\bf Description} \\\hline\endhead
{\PFAc timeout} & integer & $-1$ & Number of milliseconds to let the {\PFAc begin}, {\PFAc action}, or {\PFAc end} routine run; at or after this time, the PFA system may stop the routine with an exception (\hyperlink{hsec:exceptions}{see Sec.~\ref{sec:exceptions}}).  If negative, the execution has no timeout. \\
{\PFAc timeout.begin} & integer & {\PFAc timeout} & A specific timeout for the {\PFAc begin} routine that overrides the general {\PFAc timeout}. \\
{\PFAc timeout.action} & integer & {\PFAc timeout} & A specific timeout for the {\PFAc action} routine that overrides the general {\PFAc timeout}. \\
{\PFAc timeout.end} & integer & {\PFAc timeout} & A specific timeout for the {\PFAc end} routine that overrides the general {\PFAc timeout}. \\
\end{longtable}

\hypertarget{hsec:random}{}
\subsection{Pseudorandom number management}
\label{sec:random}

The {\PFAc randseed} top-level field specifies a seed for library functions that generate pseudorandom numbers.  If the {\PFAc randseed} is absent, the random number generator should be unpredictable: multiple runs of the same PFA document would yield different results if the output depends on pseudorandom numbers.  If a {\PFAc randseed} is provided, the random number generator should be predictable: multiple runs of the same PFA document would yield the same results on the same system.  Explicitly setting a {\PFAc randseed} is useful for tests.

The pseudorandom number generator maintains state between {\PFAc begin}, {\PFAc action}, and {\PFAc end} invocations: the generator is not reseeded with each call.  If a PFA document is used to create a battery of identical scoring engines, the {\PFAc randseed} is used to generate different seeds for all of the scoring engines: they are not guaranteed to produce identical results.

The algorithm for generating pseudorandom numbers is not specified, so different PFA implementations may use different algorithms.  Therefore, a PFA document with an explicit {\PFAc randseed} is only guaranteed to yield identical results when rerun on the same system.  On different systems, it may yield different results.

Every library function that depends on pseudorandom numbers should be seeded by the {\PFAc randseed}.  Pseudorandom functions are explicitly denoted by this specification.

\pagebreak

\section{Type system}

Rather than invent a new type system, PFA uses Avro type schemae to describe its data types.  Avro is a serialization format, but it also describes the types (sets of possible values) to be serialized or unserialized with JSON-based schemae.  Feeding Avro-formatted data into and out of a PFA scoring engine is particularly easy, since the sets of possible values that can be Avro serialized perfectly align with the sets of possible values that PFA can use in its calculations.

However, Avro serialization is by no means necessary to use with PFA: data that can be described by Avro types can be serialized many different ways.  In fact, the Avro project provides two: a binary format and a JSON format.  With the appropriate translations, CSV can be converted to and from a subset of Avro types, XML can be fully and reversibly transformed, as can many popular data formats.  The transformation of data formats and the internal representation of data in a PFA implementation are beyond the scope of this specification and should be handled in any way that the designer of a PFA system sees fit.

\hypertarget{hsec:avro-types}{}
\subsection{Avro types}
\label{sec:avro-types}

The normative definition of Avro 1.7.6 types and type schemae is \href{http://avro.apache.org/docs/1.7.6/spec.html}{provided online}.  However, the basics are duplicated here for convenience.  This section is non-normative.

The set of all expressible types is the closure under the following primitives and parameterized types.
\begin{allowedfields}
\item[null:] A type with only one value, {\PFAc null}.  This is a type-safe null in the sense that no other types are nullable unless specifically declared to be a union with type {\bf null}.
\item[boolean:] A type with only two values, {\PFAc true} and {\PFAc false}.
\item[int:] Signed whole numbers with a 32-bit range: from $-2147483648$ to $2147483647$ inclusive.
\item[long:] Signed whole numbers with a 64-bit range: from $-9223372036854775808$ to $9223372036854775807$.
\item[float:] Signed fractional numbers with 32-bit binary precision as defined by \href{http://dx.doi.org/10.1109%2FIEEESTD.2008.4610935}{IEEE 754}.
\item[double:] Signed fractional numbers with 64-bit binary precision according to the same standard.
\item[string:] Strings of text characters that can be encoded in \href{http://www.unicode.org/standard/standard.html}{Unicode}.
\item[bytes:] Arrays of uninterpreted bytes with any length.
\item[fixed({\PFAtp L}):] Named arrays of uninterpreted bytes with length {\PFAtp L} (integer).
\item[enum({\PFAtp S}):] Named enumeration of a finite set of symbols {\PFAtp S} (ordered list of strings).
\item[array({\PFAtp X}):] Homogeneous array of type {\PFAtp X} (Avro type) with any length.
\item[map({\PFAtp X}):] Homogeneous map from strings to type {\PFAtp X} (Avro type).  The keys of all maps must be strings (just like JSON).
\item[record({\PFAtp F}):] Heterogeneous record of fields {\PFAtp F} (named slots with Avro types).  This is a product type, since the possible values that a record can have is the Cartesian product of the possible values that each field can have.
\item[union({\PFAtp T}):] Union of types {\PFAtp T}.  This is a sum type, since the possible values that a union can have is sum of types {\PFAtp T}.
\end{allowedfields}

\noindent\begin{minipage}{\linewidth}
\indent This type system has the following limitations and remediations.
\begin{itemize}
\item Arrays and maps must be homogeneous (all elements have the same, specified type).  This is sufficient for most mathematical applications and the restriction helps to eliminate common mistakes.  Also, it makes some significant optimizations possible that are difficult or impossible in dynamic languages.
\end{itemize}
\end{minipage}

\vspace{-0.15 cm}
\begin{itemize}
\item Map keys must be strings.  If an application must represent a map whose keys are not strings, one can define a unique string representation for each key and look up items by first transforming to the string representation.

\item There is no set or multiset type.  This can be emulated with arrays and PFA's \hyperlink{hsec:set-like}{set-like functions} or a map from string-valued keys to {\PFAc null}.

\item Circular references are not possible, as there are no pointers or references.  However, data structures with conceptual loops can be emulated through weak references in a map.  For example, an arbitrary directed graph can be described as a map of arrays of strings: each key is a node and each element of an array is a link to another node.  These references are weak because there is no guarantee that a key exists for every array element.

The lack of circular references is, in some ways, an advantage.  Non-circular data can be more easily serialized without the possibility of infinite loops.  Immutable data can take advantage of more structural sharing since data structures are purely tree-like.

Note that recursively defined types {\it are} possible.  A record {\PFAtp X} could have one or more fields that are unions of {\PFAtp X} and {\PFAtp Y}, or it could have a field that is an array or map of {\PFAtp X}.  The first case would describe a tree of nodes {\PFAtp X} with a fixed number of named branches, terminating in leaves of type {\PFAtp Y}.  (This is how decision trees are described in PFA; the scores have type {\PFAtp Y}.)  The second case would describe a tree of nodes {\PFAtp X} with arbitrarily many branches at each node, terminating in empty arrays or maps.

\item To make a type such as {\bf string} nullable, one must construct a union of {\bf string} and {\bf null}.  This union type cannot be passed into functions that expect a {\bf string}.

Again, this restriction can be an advantage.  It is often known as a type-safe null: in the example above, string functions can still be used, but only after explicitly handling the {\bf null} case.  In PFA, one would use a \hyperlink{hsec:casting}{cast-cases} special form to split the program flow into a branch that handles the {\bf string} case and a branch that handles the {\bf null} case, usually by specifying a rule that replaces {\PFAc null} with a string.  This restriction eliminates the possibility of null pointer exceptions at runtime.

Most library functions in PFA interpret {\PFAc null} as a missing value.  Missing value handling is an important consideration in many statistical analyses, so PFA has a \hyperlink{hsec:impute}{suite of functions} for addressing this case.
\end{itemize}

The advantages of this type system are that (a) it aligns well with types already used by major data pipeline tools (binary Avro and, with some transformation, Thrift and Protocol Buffers), (b) it is easy to represent as JSON or XML (the lack of circular references is particularly helpful), (c) any type is nullable, including primitives, (d) Avro's rules for schema resolution can be reinterpreted as type promotion for type inference (\hyperlink{hsec:type-inference}{see Sec.~\ref{sec:type-inference}}), (e) all types have a strict ordering (see \href{http://avro.apache.org/docs/1.7.6/spec.html#order}{Avro sort order specification}), and (f) the type schemae are JSON objects and strings, which fit seamlessly into a PFA document.

\subsection{Type schemae in the PFA document}

An Avro type schema can be a JSON object or a string.  JSON objects construct parameterized types, while strings specify type primitives or reference previously defined types.  Some PFA top-level fields and member values of special forms must be Avro schemae: these schema are simply included inline with the JSON representing the rest of the PFA document.

Below is a summary of the schema syntax that is relevant for PFA.  All \hyperlink{http://avro.apache.org/docs/1.7.6/spec.html}{Avro schema elements} must be accepted by a PFA reader, but these are the only ones that influence PFA.

The following strings are type primatives: ``null'', ``boolean'', ``int'', ``long'', ``float'', ``double'', ``string'', ``bytes''.  Other strings are either previously defined named types or they are invalid.  The form {\PFAc \{"type":$\!$ "X"\}} for string {\PFAtp X} is equivalent to the string on its own.

A byte array with name {\PFAtp N} and fixed length {\PFAtp L} is specified by the form {\PFAc \{"type":$\!$ "fixed", "name":$\!$ "N", "namespace":$\!$ "NS", "size":$\!$ L\}}.  The namespace is optional, but the name is not.  The length {\PFAtp L} must be a JSON integer.  Avro fixed types have additional object members, but they are not relevant for PFA.

An enumeration with name {\PFAtp N} and symbols {\PFAtp S} is specified by the form {\PFAc \{"type":$\!$ "enum", "name":$\!$ "N", "namespace":$\!$ "NS", "symbols":$\!$ S\}}.  The namespace is optional, but the name is not.  The symbols {\PFAtp S} must be a JSON array of strings.  Avro enumeration types have additional object members, but they are not relevant for PFA.

An array with elements of type {\PFAtp X} is specified by the form {\PFAc \{"type": "array", "items": X\}}.  An array does not accept a name or any other member values.

An map with values of type {\PFAtp X} is specified by the form {\PFAc \{"type": "map", "values": X\}}.  A map does not accept a name or any other member values.

A record with name {\PFAtp N} and fields {\PFAtp F} is specified by the form {\PFAc \{"type":$\!$ "record", "name":$\!$ "N", "namespace":$\!$ "NS", "fields":$\!$ F\}}.  The namespace is optional, but the name is not.  The fields {\PFAtp F} must be JSON objects with the following form: {\PFAc \{"name": "FN", "type": "FT", "default": D, "order": O\}} where {\PFAc name} and {\PFAc type} are required and {\PFAc default} and {\PFAc order} are not.  The default {\PFAtp D} is encoded in the Avro-JSON format and provides a default value if the input data stream is missing one.  The order {\PFAc O} is one of these strings: ``ascending'', ``descending'', and ``ignore'', and it defines the sort order for the record.  Avro record types and field types have additional object members, but they are not relevant for PFA.

A union of types {\PFAtp T1} \ldots {\PFAtp TN} is specified by a JSON array form {\PFAc [T \ldots\ TN]}.

If the Avro implementation used by a PFA system supports \href{http://avro.apache.org/docs/1.7.6/spec.html#Aliases}{aliases} for schema resolution, the aliases should be used for type inference (\hyperlink{hsec:type-inference}{see Sec.~\ref{sec:type-inference}}).  Aliases only apply to named types and record fields.

Avro schema parsing is usually implemented as a stateful process, in which the parser remembers previously named types and recognizes its namespace-qualified name in a JSON string as representing the type.  This is especially important for recursively defined types.  A PFA document may have many type schemae embedded within it, often as member values of JSON objects.  Systems that load JSON objects into hash-tables cannot guarantee that the order of JSON object members is preserved, which could cause schemae to be read in any order.

Therefore, PFA implementations must pass Avro schemae to be parsed in an order that resolves dependencies or PFA implementations must parse the schemae themselves in an order that resolves dependencies.  PFA documents must define named types (as a JSON object) exactly once and reference them (as a string) elsewhere.

\hypertarget{hsec:type-inference}{}
\subsection{Type inference}
\label{sec:type-inference}

PFA uses a near-minimum of type annotations for static type analysis.  Only the inputs to every calculation, which are function parameters, literal constants, inline arrays/maps/records, the symbols {\PFAc input} and {\PFAc tally}, and cell/pool definitions, and the outputs of every calculation, which are function return values and the scoring engine {\PFAc output}, need to be specified.  Unlike traditional languages (e.g.\ C or Java), the types of new variables are not specified: they are inferred through their initialization expressions (and would be redundant if supplied).

With these annotations, the type check algorithm is simple.  Every expression is a tree of subexpressions, whose leaves are either references to previously defined symbols, function parameters, cells, or pools (with known type) or constants (with specified type).  Every function and special form has a type signature that may accept its arguments, in which case type-checking continues toward the root of the tree, or reject its arguments, in which case the PFA document fails with a semantic error.  Every function and special form has a return type, which may depend on the types of its arguments (but not the values of its arguments, which are only known at runtime).  Arguments and return types should be recursively checked until the root of the tree (the type of the expression as a whole) is reached.  This derived type is checked against the declared function return type or {\PFAc output}.  If the declared type does not accept the derived type, the PFA document is rejected with a semantic error.

Some special forms take a JSON array of expressions and either apply no return type constraint or only constrain the last expression, which is used as a return value.  Each case is explicitly specified in \hyperlink{hsec:expressions}{Sec.~\ref{sec:expressions}}.

In passing, we note that the type annotations could have been more minimal if return types were not required, and some input types could, in principle, be inferred from their position in a function argument list.  However, an explicit {\PFAc output} allows a PFA system or casual observer to quickly determine if a scoring engine will fit into a given workflow, in which the input types and output types are constrained by data pipelines.  Function return values cannot always be omitted: recursive functions cannot determine their return type from parameters only, for instance.  Inferring input types from parents or siblings in the expression tree unnecessarily complicates the type-check algorithm, which most PFA systems should implement.  The algorithm chosen for PFA is strictly local--- only subexpressions and previously defined symbols are needed to infer an expression type--- and uniform--- the same rules apply regardless of the function's call graph.

\subsection{Type resolution, promotion, and covariance}

At each step in the type inference algorithm, the expected type or type pattern is checked against the actual or derived type.  All types have a non-commutative, binary ``accepts'' relation, in which ``A accepts B'' means that B is an acceptable actual type for expected type A.  For example, ``double accepts int'' because integers are a subset of double-precision floating point numbers, and any function that needs a double must be able to use an int instead.

Even though Avro is a serialization protocol, it defines a suite of type promotion rules for the sake of schema resolution.  In Avro, these rules are used to determine if an old version of a schema is compatible with a new version of a schema: for instance, if the old schema defines a variable as an int and the new schema defines it as a double, the old serialized dataset is forward-compatible--- it can be used in an application as though it had the new schema.  PFA uses the same rules to promote data through an expression.

These rules are described in the \href{http://avro.apache.org/docs/1.7.6/spec.html#Schema+Resolution}{Schema Resolution section} of the Avro specification, but it is reviewed here with an emphasis on how these rules are used in PFA type inference.




copy Avro rules here (and check them in REPL)

\subsection{Generic library function signatures}

including wildcards and wildrecords; typeset them the same way as they are used in libfcn reference

solution to an equation

promotes conflicting label matches to a union

\pagebreak

\section{Symbols, scope, and data structures}

implicit garbage collector; no restriction on the choice of garbage collector (use whatever is available on your system!)

\hypertarget{hsec:immutable}{}
\subsection{Immutable data, reassignable symbols}
\label{sec:immutable}

\subsection{Expression-level scope and mutation restrictions}

\pagebreak

\section{User-defined functions}

\hypertarget{hsec:fcndef}{}
\label{form:fcndef}

        %% else if (keys == Set("params", "ret", "do"))                 FcnDef(_params, _ret, _body, Some(pos(dot, _at)))

\hypertarget{hsec:fcnref}{}
\label{form:fcnref}

        %% else if (keys == Set("fcnref"))                              FcnRef(_fcnref, Some(pos(dot, _at)))

\subsection{Syntax and scope}

\subsection{Anonymous callbacks and function references}

\pagebreak

\hypertarget{hsec:expressions}{}
\section{Expressions}
\label{sec:expressions}

Special forms and ordinary function calls

\hypertarget{hsec:function-call}{}
\subsection{Function calls}
\label{sec:function-call}

\hypertarget{hsec:symbol-ref}{}
\subsection{Symbol references}
\label{sec:symbol-ref}

\hypertarget{hsec:literals}{}
\subsection{Literal values}
\label{sec:literals}

        %% if (keys == Set("int"))                                      LiteralInt(_int, Some(pos(dot, _at)))
        %% else if (keys == Set("long"))                                LiteralLong(_long, Some(pos(dot, _at)))
        %% else if (keys == Set("float"))                               LiteralFloat(_float, Some(pos(dot, _at)))
        %% else if (keys == Set("double"))                              LiteralDouble(_double, Some(pos(dot, _at)))
        %% else if (keys == Set("string"))                              LiteralString(_string, Some(pos(dot, _at)))
        %% else if (keys == Set("base64"))                              LiteralBase64(_bytes, Some(pos(dot, _at)))
        %% else if (keys == Set("type", "value"))                       Literal(_avroType, _value, Some(pos(dot, _at)))

% short-cut for strings: ["x"] to mean {"string": "x"}

\hypertarget{hsec:new-form}{}
\subsection{Creating arrays, maps, and records}
\label{sec:new-form}

        %% else if (keys == Set("new", "type")  &&  _newObject != null) NewObject(_newObject, _avroType, avroTypeBuilder, Some(pos(dot, _at)))
        %% else if (keys == Set("new", "type")  &&  _newArray != null)  NewArray(_newArray, _avroType, avroTypeBuilder, Some(pos(dot, _at)))

\hypertarget{hsec:let-set}{}
\subsection{Symbol assignment and reassignment}
\label{sec:let-set}

        %% else if (keys == Set("let"))                                 Let(_let, Some(pos(dot, _at)))
        %% else if (keys == Set("set"))                                 SetVar(_set, Some(pos(dot, _at)))

\hypertarget{hsec:attr-form}{}
\subsection{Extracting from and updating arrays, maps, and records}
\label{sec:attr-form}

        %% else if (keys == Set("attr", "path"))                        AttrGet(_attr, _path, Some(pos(dot, _at)))
        %% else if (keys == Set("attr", "path", "to"))                  AttrTo(_attr, _path, _to, Some(pos(dot, _at)))

% short-cut: "name.path.elements.0.etc"

\hypertarget{hsec:cell-pool-forms}{}
\subsection{Extracting from and updating cells and pools}
\label{sec:cell-pool-forms}

        %% else if (keys == Set("cell")  ||
        %%          keys == Set("cell", "path"))                        CellGet(_cell, _path, Some(pos(dot, _at)))
        %% else if (keys == Set("cell", "to")  ||
        %%          keys == Set("cell", "path", "to"))                  CellTo(_cell, _path, _to, Some(pos(dot, _at)))
        %% else if (keys == Set("pool", "path"))                        PoolGet(_pool, _path, Some(pos(dot, _at)))
        %% else if (keys == Set("pool", "path", "to")  ||
        %%          keys == Set("pool", "path", "to", "init"))          PoolTo(_pool, _path, _to, _init, Some(pos(dot, _at)))

% short-cut: "name.path.elements.0.etc"

\hypertarget{hsec:doblocks}{}
\subsection{Do blocks}
\label{sec:doblocks}

        %% else if (keys == Set("do"))                                  Do(_body, Some(pos(dot, _at)))

\hypertarget{hsec:conditionals}{}
\subsection{Conditionals: if and cond}
\label{sec:conditionals}

        %% else if (keys == Set("if", "then"))                          If(_ifPredicate, _thenClause, None, Some(pos(dot, _at)))
        %% else if (keys == Set("if", "then", "else"))                  If(_ifPredicate, _thenClause, Some(_elseClause), Some(pos(dot, _at)))
        %% else if (keys == Set("cond"))                                Cond(_cond.map(_.asInstanceOf[If]), None, Some(pos(dot, _at)))
        %% else if (keys == Set("cond", "else"))                        Cond(_cond.map(_.asInstanceOf[If]), Some(_elseClause), Some(pos(dot, _at)))

\hypertarget{hsec:whileloops}{}
\subsection{While loops: pretest and posttest}
\label{sec:whileloops}

        %% else if (keys == Set("while", "do"))                         While(_whilePredicate, _body, Some(pos(dot, _at)))
        %% else if (keys == Set("do", "until"))                         DoUntil(_body, _until, Some(pos(dot, _at)))

\hypertarget{hsec:forloops}{}
\subsection{For loops: by index, array element, and key-value}
\label{sec:forloops}

        %% else if (keys == Set("for", "until", "step", "do")  ||
        %%          keys == Set("for", "until", "step", "do", "seq"))   For(_forlet, _until, _forstep, _body, _seq, Some(pos(dot, _at)))
        %% else if (keys == Set("foreach", "in", "do")  ||
        %%          keys == Set("foreach", "in", "do", "seq"))          Foreach(_foreach, _in, _body, _seq, Some(pos(dot, _at)))
        %% else if (keys == Set("forkey", "forval", "in", "do"))        Forkeyval(_forkey, _forval, _in, _body, Some(pos(dot, _at)))

\hypertarget{hsec:casting}{}
\subsection{Type-safe casting}
\label{sec:casting}

        %% else if (keys == Set("cast", "cases")  ||
        %%          keys == Set("cast", "cases", "partial"))            CastBlock(_cast, _cases, _partial, Some(pos(dot, _at)))
        %% else if (keys == Set("upcast", "as"))                        Upcast(_upcast, _as, Some(pos(dot, _at)))

\hypertarget{hsec:inline-doc}{}
\subsection{Inline documentation}
\label{sec:inline-doc}

        %% else if (keys == Set("doc"))                                 Doc(_doc, Some(pos(dot, _at)))

\hypertarget{hsec:exception-form}{}
\subsection{User-defined exceptions}
\label{sec:exception-form}

        %% else if (keys == Set("error"))                               Error(_error, None, Some(pos(dot, _at)))
        %% else if (keys == Set("error", "code"))                       Error(_error, Some(_code), Some(pos(dot, _at)))

\hypertarget{hsec:logs}{}
\subsection{Log messages}
\label{sec:logs}

        %% else if (keys == Set("log"))                                 Log(_log, None, Some(pos(dot, _at)))
        %% else if (keys == Set("log", "namespace"))                    Log(_log, Some(_namespace), Some(pos(dot, _at)))

\pagebreak

\section{Core library}

\subsection{Basic arithmetic}

\subsubsection{Addition of two values ($+$)}
% \libfcn{+}

\subsubsection{Subtraction ($-$)}
% \libfcn{-}

\subsubsection{Multiplication of two values (*)}
% \libfcn{*}

\subsubsection{Floating-point division (/)}
% \libfcn{/}

\subsubsection{Integer division (//)}
% \libfcn{//}

\subsubsection{Negation (u$-$)}
% \libfcn{u-}

\subsubsection{Modulo (\%)}
% \libfcn{\%}

\subsubsection{Remainder (\%\%)}
% \libfcn{\%\%}

\subsubsection{Raising to a power (**)}
% \libfcn{**}

\subsection{Comparison operators}

Avro defines a \href{http://avro.apache.org/docs/1.7.6/spec.html#order}{sort order} for every pair of values with a compatible type, so any two objects of compatible type can be compared in PFA.

\subsubsection{General comparision (cmp)}
% \libfcn{cmp}

\subsubsection{Equality (==)}
% \libfcn{==}

\subsubsection{Inequality (!=)}
% \libfcn{!=}

\subsubsection{Less than (<)}
% \libfcn{<}

\subsubsection{Less than or equal to (<=)}
% \libfcn{<=}

\subsubsection{Greater than (>)}
% \libfcn{>}

\subsubsection{Greater than or equal to (>=)}
% \libfcn{>=}

\subsubsection{Maximum of two values (max)}
% \libfcn{max}

\subsubsection{Minimum of two values (min)}
% \libfcn{min}

\subsection{Logical operators}

\subsubsection{Logical and (and)}
% \libfcn{and}

\subsubsection{Logical or (or)}
% \libfcn{or}

\subsubsection{Logical xor (xor)}
% \libfcn{xor}

\subsubsection{Logical not (not)}
% \libfcn{not}

\subsection{Bitwise arithmetic}

\subsubsection{Bitwise and (\&)}
% \libfcn{\&}

\subsubsection{Bitwise or (|)}
% \libfcn{|}

\subsubsection{Bitwise xor (\^{})}
% \libfcn{\^{}}

\subsubsection{Bitwise not (\textasciitilde{})}
% \libfcn{TILDE}

\pagebreak

\section{Math library}

\subsection{Constants}

Constants such as $\pi$ and $e$ are represented as stateless functions with no arguments.  Specific implementations may choose to replace the function call with its inline value.

\subsubsection{Archimedes' constant $\pi$ (m.pi)}
% \libfcn{m.pi}

\subsubsection{Euler's constant $e$ (m.e)}
% \libfcn{m.e}

\subsection{Common functions}

\subsubsection{Square root (m.sqrt)}
% \libfcn{m.sqrt}

\subsubsection{Hypotnuse (m.hypot)}
% \libfcn{m.hypot}

\subsubsection{Trigonometric sine (m.sin)}
% \libfcn{m.sin}

\subsubsection{Trigonometric cosine (m.cos)}
% \libfcn{m.cos}

\subsubsection{Trigonometric tangent (m.tan)}
% \libfcn{m.tan}

\subsubsection{Inverse trigonometric sine (m.asin)}
% \libfcn{m.asin}

\subsubsection{Inverse trigonometric cosine (m.acos)}
% \libfcn{m.acos}

\subsubsection{Inverse trigonometric tangent (m.atan)}
% \libfcn{m.atan}

\subsubsection{Robust inverse trigonometric tangent (m.atan2)}
% \libfcn{m.atan2}

\subsubsection{Hyperbolic sine (m.sinh)}
% \libfcn{m.sinh}

\subsubsection{Hyperbolic cosine (m.cosh)}
% \libfcn{m.cosh}

\subsubsection{Hyperbolic tangent (m.tanh)}
% \libfcn{m.tanh}

\subsubsection{Natural exponential (m.exp)}
% \libfcn{m.exp}

\subsubsection{Natural exponential minus one (m.expm1)}
% \libfcn{m.expm1}

\subsubsection{Natural logarithm (m.ln)}
% \libfcn{m.ln}

\subsubsection{Logarithm base 10 (m.log10)}
% \libfcn{m.log10}

\subsubsection{Arbitrary logarithm (m.log)}
% \libfcn{m.log}

\subsubsection{Natural logarithm of one plus square (m.ln1p)}
% \libfcn{m.ln1p}

\subsection{Rounding}

\subsubsection{Absolute value (m.abs)}
% \libfcn{m.abs}

\subsubsection{Floor (m.floor)}
% \libfcn{m.floor}

\subsubsection{Ceiling (m.ceil)}
% \libfcn{m.ceil}

\subsubsection{Simple rounding (m.round)}
% \libfcn{m.round}

\subsubsection{Unbiased rounding (m.rint)}
% \libfcn{m.rint}

\subsubsection{Threshold function (m.signum)}
% \libfcn{m.signum}

\subsubsection{Copy sign (m.copysign)}
% \libfcn{m.copysign}

\subsection{Linear algebra}

including named row/col matrices

\pagebreak

\section{String manipulation}

Strings are immutable, so none of the following functions modifies a string in-place.  Some return a modified version of the original string.

\subsection{Basic access}

\subsubsection{Length (s.len)}
% \libfcn{s.len}

\subsubsection{Extract substring (s.substr)}
% \libfcn{s.substr}

\subsubsection{Modify substring (s.substrto)}
% \libfcn{s.substrto}

\subsection{Search and replace}

\subsubsection{Contains (s.contains)}
% \libfcn{s.contains}

\subsubsection{Count instances (s.count)}
% \libfcn{s.count}

\subsubsection{Find first index (s.index)}
% \libfcn{s.index}

\subsubsection{Find last index (s.rindex)}
% \libfcn{s.rindex}

\subsubsection{Check start (s.startswith)}
% \libfcn{s.startswith}

\subsubsection{Check end (s.endswith)}
% \libfcn{s.endswith}

\subsection{Conversions to or from other types}

\subsubsection{Join an array of strings (s.join)}
% \libfcn{s.join}

\subsubsection{Split into an array of strings (s.split)}
% \libfcn{s.split}

\subsection{Conversions to or from other strings}

\subsubsection{Concatenate two strings (s.concat)}
% \libfcn{s.concat}

\subsubsection{Repeat pattern (s.repeat)}
% \libfcn{s.repeat}

\subsubsection{Lowercase (s.lower)}
% \libfcn{s.lower}

\subsubsection{Uppercase (s.upper)}
% \libfcn{s.upper}

\subsubsection{Left-strip (s.lstrip)}
% \libfcn{s.lstrip}

\subsubsection{Right-strip (s.rstrip)}
% \libfcn{s.rstrip}

\subsubsection{Strip both ends (s.strip)}
% \libfcn{s.strip}

\subsubsection{Replace all matches (s.replaceall)}
% \libfcn{s.replaceall}

\subsubsection{Replace first match (s.replacefirst)}
% \libfcn{s.replacefirst}

\subsubsection{Replace last match (s.replacelast)}
% \libfcn{s.replacelast}

\subsubsection{Translate characters (s.translate)}
% \libfcn{s.translate}

\subsection{Regular Expressions}

and stemming

\pagebreak

\section{Array Manipulation}

\subsection{Basic access}

\subsubsection{Length (a.len)}
% \libfcn{a.len}

\subsubsection{Extract subsequence (a.subseq)}
% \libfcn{a.subseq}

\subsubsection{Modify subsequence (a.subseqto)}
% \libfcn{a.subseqto}

\subsection{Search and replace}

\subsubsection{Contains (a.contains)}
% \libfcn{a.contains}

\subsubsection{Count instances (a.count)}
% \libfcn{a.count}

\subsubsection{Count instances by predicate (a.countPredicate)}
libfcn{a.countPredicate}

\subsubsection{Find first index (a.index)}
% \libfcn{a.index}

\subsubsection{Find last index (a.rindex)}
% \libfcn{a.rindex}

\subsubsection{Check start (a.startswith)}
% \libfcn{a.startswith}

\subsubsection{Check end (a.endswith)}
% \libfcn{a.endswith}

\subsection{Manipulation}

\subsubsection{Concatenate two arrays (a.concat)}
% \libfcn{a.concat}

\subsubsection{Append (a.append)}
% \libfcn{a.append}

\subsubsection{Insert or prepend (a.insert)}
% \libfcn{a.insert}

\subsubsection{Replace item (a.replace)}
% \libfcn{a.replace}

\subsubsection{Remove item (a.remove)}
% \libfcn{a.remove}

\subsection{Reordering}

\subsubsection{Sort (a.sort)}
% \libfcn{a.sort}

\subsubsection{Sort with a less-than function (a.sortLT)}
% \libfcn{a.sortLT}

\subsubsection{Randomly shuffle array (a.shuffle)}
% \libfcn{a.shuffle}

\subsubsection{Reverse order (a.reverse)}
% \libfcn{a.reverse}

\subsection{Extreme values}

\subsubsection{Maximum of all values (a.max)}
% \libfcn{a.max}

\subsubsection{Minimum of all values (a.min)}
% \libfcn{a.min}

\subsubsection{Maximum with a less-than function (a.maxLT)}
% \libfcn{a.maxLT}

\subsubsection{Minimum with a less-than function (a.minLT)}
% \libfcn{a.minLT}

\subsubsection{Maximum $N$ items (a.maxN)}
% \libfcn{a.maxN}

\subsubsection{Minimum $N$ items (a.minN)}
% \libfcn{a.minN}

\subsubsection{Maximum $N$ with a less-than function (a.maxNLT)}
% \libfcn{a.maxNLT}

\subsubsection{Minimum $N$ with a less-than function (a.minNLT)}
% \libfcn{a.minNLT}

\subsubsection{Argument maximum (a.argmax)}
% \libfcn{a.argmax}

\subsubsection{Argument minimum (a.argmin)}
% \libfcn{a.argmin}

\subsubsection{Argument maximum with a less-than function (a.argmaxLT)}
% \libfcn{a.argmaxLT}

\subsubsection{Argument minimum with a less-than function (a.argminLT)}
% \libfcn{a.argminLT}

\subsubsection{Maximum $N$ arguments (a.argmaxN)}
% \libfcn{a.argmaxN}

\subsubsection{Minimum $N$ arguments (a.argminN)}
% \libfcn{a.argminN}

\subsubsection{Maximum $N$ arguments with a less-than function (a.argmaxNLT)}
% \libfcn{a.argmaxNLT}

\subsubsection{Minimum $N$ arguments with a less-than function (a.argminNLT)}
% \libfcn{a.argminNLT}

\subsection{Numerical combinations}

\subsubsection{Add all array values (a.sum)}
% \libfcn{a.sum}

\subsubsection{Multiply all array values (a.product)}
% \libfcn{a.product}

\subsubsection{Sum of logarithms (a.lnsum)}
% \libfcn{a.lnsum}

\subsubsection{Arithmetic mean (a.mean)}
% \libfcn{a.mean}

\subsubsection{Geometric mean (a.geomean)}
% \libfcn{a.geomean}

\subsubsection{Median (a.median)}
% \libfcn{a.median}

\subsubsection{Mode, or most common value (a.mode)}
% \libfcn{a.mode}

\hypertarget{hsec:set-like}{}
\subsection{Set or set-like functions}
\label{sec:set-like}

PFA does not have a set datatype, but arrays can be interpreted as sets with the following functions.

\subsubsection{Distinct items (a.distinct)}
% \libfcn{a.distinct}

\subsubsection{Set equality (a.seteq)}
% \libfcn{a.seteq}

\subsubsection{Union (a.union)}
% \libfcn{a.union}

\subsubsection{Intersection (a.intersect)}
% \libfcn{a.intersect}

\subsubsection{Set difference (a.diff)}
% \libfcn{a.diff}

\subsubsection{Symmetric set difference (a.symdiff)}
% \libfcn{a.symdiff}

\subsubsection{Subset check (a.subset)}
% \libfcn{a.subset}

\subsubsection{Disjointness check (a.disjoint)}
% \libfcn{a.disjoint}

\subsection{Functional programming}

\subsubsection{Map array items with function (a.map)}
% \libfcn{a.map}

\subsubsection{Filter array items with function (a.filter)}
% \libfcn{a.filter}

\subsubsection{Filter and map (a.filtermap)}
% \libfcn{a.filtermap}

\subsubsection{Map and flatten (a.flatmap)}
% \libfcn{a.flatmap}

\subsubsection{Reduce array items to a single value (a.reduce)}
% \libfcn{a.reduce}

\subsubsection{Right-to-left reduce (a.reduceright)}
% \libfcn{a.reduceright}

\subsubsection{Fold array items to another type (a.fold)}
% \libfcn{a.fold}

\subsubsection{Right-to-left fold (a.foldright)}
% \libfcn{a.foldright}

\subsubsection{Take items until predicate is false (a.takeWhile)}
% \libfcn{a.takeWhile}

\subsubsection{Drop items until predicate is true (a.dropWhile)}
% \libfcn{a.dropWhile}

\subsection{Functional tests}

\subsubsection{Existential check, $\exists$ (a.any)}
% \libfcn{a.any}

\subsubsection{Univeral check, $\forall$ (a.all)}
% \libfcn{a.all}

\subsubsection{Pairwise check of two arrays (a.corresponds)}
% \libfcn{a.corresponds}

\subsection{Restructuring}

\subsubsection{Sliding window (a.slidingWindow)}
% \libfcn{a.slidingWindow}

\subsubsection{Unique combinations of a fixed size (a.combinations)}
% \libfcn{a.combinations}

\subsubsection{Permutations (a.permutations)}
% \libfcn{a.permutations}

\subsubsection{Flatten array (a.flatten)}
% \libfcn{a.flatten}

\subsubsection{Group items by category (a.groupby)}
% \libfcn{a.groupby}

\pagebreak

\section{Manipulation of other data structures}

\subsection{Map}

\subsection{Record}

\subsection{Enum}

\subsection{Fixed}

\pagebreak

\section{Missing data handling}

\hypertarget{hsec:impute}{}
\subsection{Impute library}
\label{sec:impute}

\subsubsection{Skip record (impute.errorOnNull)}
% \libfcn{impute.errorOnNull}

\subsubsection{Replace with default (impute.defaultOnNull)}
% \libfcn{impute.defaultOnNull}

\pagebreak

\section{Aggregation}

SQL-like functions

group-by tables

CUSUM

\pagebreak

\section{Descriptive statistics libraries}

\subsection{Sample statistics}

\subsubsection{Update aggregated mean (stat.sample.updateMean)}
% \libfcn{stat.sample.updateMean}

\subsubsection{Compute aggregated mean (stat.sample.mean)}
% \libfcn{stat.sample.mean}

accumulated mean, median(?)

\pagebreak

\section{Data mining models}

\subsection{Decision and regression Trees}

\subsubsection{Tree walk with simple predicates (model.tree.simpleWalk)}
% \libfcn{model.tree.simpleWalk}

\subsubsection{Tree walk with user-defined predicates (model.tree.predicateWalk)}
% \libfcn{model.tree.predicateWalk}

\subsection{Cluster models}

\subsection{Regression}

\subsection{Neural networks}

\subsection{Support vector machines}

\end{document}
